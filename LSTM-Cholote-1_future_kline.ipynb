{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BIERZE ZAKRES KILKU WIERSZY W HISTORII I SZACUJE JAKA BEDZIER WARTOSC CLOSE PRICE JEDNOSTKOWA W DANEJ X ILOSCIOWO KOLEJNYM NUMERZE SWIECY\n",
    "# \n",
    "# TEORETYCZNIE MOZNABY STWORZYC 50 MODELI, KAZDY MIALBY DELAY CZYLI SWIECA W PRZYSZLOSCI KTORA NALEZY OKRESLIC KOLEJNA WARTOSC OD 1 DO 50 I Z KAZDEGO MODELU BRAC WYNIK JAKA BEDZIE WARTOSC X KOLEJNEJ SWIEY, SKLEJAC W CALOSC I WYPLUWAC"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 17:59:59.557739: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-18 17:59:59.684780: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 18:00:00.247726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import MaxPooling1D, Flatten, GRU, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:00:01.240631763Z",
     "start_time": "2024-01-18T16:59:59.128381207Z"
    }
   },
   "id": "9c45212b2fbbe839",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][3]\n",
    "\n",
    "        yield samples, targets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:00:27.823679635Z",
     "start_time": "2024-01-18T17:00:27.798752990Z"
    }
   },
   "id": "6dda21348faf8029",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC_KLINES_MONTHLY_12_2020_PER_5m 8938\n",
      "      openPrice  highPrice  lowPrice  closePrice  volume  quoteAssetVolume  \\\n",
      "0      18880.71   18911.46  18859.38    18887.13  223.97        4230029.78   \n",
      "1      18887.13   18979.99  18887.13    18919.62  295.66        5602893.17   \n",
      "2      18919.62   18940.05  18883.32    18892.30  215.83        4081178.18   \n",
      "3      18892.31   18933.68  18855.19    18902.11  188.29        3559280.31   \n",
      "4      18902.10   18983.46  18902.10    18941.38  182.43        3457804.74   \n",
      "...         ...        ...       ...         ...     ...               ...   \n",
      "8933   29189.60   29204.66  29145.49    29145.49  101.61        2964249.59   \n",
      "8934   29145.49   29177.41  29127.60    29172.83  129.65        3779709.94   \n",
      "8935   29172.84   29199.00  29163.69    29197.48   76.62        2236044.84   \n",
      "8936   29197.93   29199.00  29160.02    29174.49  100.82        2942375.59   \n",
      "8937   29174.49   29202.67  29173.98    29182.99  123.60        3608281.44   \n",
      "\n",
      "      tradesAmount  takerButBase  takerBuyQuote  close_minus5_d  ...  \\\n",
      "0             5682        106.13     2004785.31          148.28  ...   \n",
      "1             5795        139.42     2641796.72           77.45  ...   \n",
      "2             4616        112.51     2127723.33          153.48  ...   \n",
      "3             4413         69.41     1312156.09           93.68  ...   \n",
      "4             5399         90.31     1711836.39           60.66  ...   \n",
      "...            ...           ...            ...             ...  ...   \n",
      "8933          2650         37.91     1105873.25           41.59  ...   \n",
      "8934          2985         56.75     1654514.87          140.59  ...   \n",
      "8935          2292         42.02     1226201.77           84.64  ...   \n",
      "8936          2306         41.22     1202930.92           44.39  ...   \n",
      "8937          2463         63.05     1840613.19           -6.61  ...   \n",
      "\n",
      "        psl_55  psl_80    psl_99   psl_150       pvo      pvos      pvoh  \\\n",
      "0     52.72727   52.50  50.50505  49.33333 -15.55719 -17.11041   1.55322   \n",
      "1     52.72727   52.50  50.50505  50.00000 -14.52264 -16.59286   2.07022   \n",
      "2     52.72727   52.50  49.49495  50.00000 -15.69386 -16.41306   0.71920   \n",
      "3     52.72727   53.75  50.50505  50.00000 -17.32748 -16.59594  -0.73154   \n",
      "4     52.72727   55.00  51.51515  50.00000 -18.74896 -17.02655  -1.72241   \n",
      "...        ...     ...       ...       ...       ...       ...       ...   \n",
      "8933  52.72727   51.25  50.50505  52.00000  16.46183  19.78353  -3.32171   \n",
      "8934  52.72727   51.25  51.51515  52.00000  12.25890  18.27861  -6.01971   \n",
      "8935  52.72727   52.50  51.51515  52.00000   6.31307  15.88550  -9.57243   \n",
      "8936  52.72727   52.50  50.50505  51.33333   2.45509  13.19942 -10.74433   \n",
      "8937  54.54545   53.75  50.50505  51.33333   0.43865  10.64727 -10.20861   \n",
      "\n",
      "           qqe      qqel      qqes  \n",
      "0     46.81002   0.00000  46.81002  \n",
      "1     42.14824  42.14824   0.00000  \n",
      "2     42.66091  42.66091   0.00000  \n",
      "3     43.24191  43.24191   0.00000  \n",
      "4     44.53218  44.53218   0.00000  \n",
      "...        ...       ...       ...  \n",
      "8933  45.78975   0.00000  45.78975  \n",
      "8934  45.78975   0.00000  45.78975  \n",
      "8935  40.31081  40.31081   0.00000  \n",
      "8936  40.54353  40.54353   0.00000  \n",
      "8937  41.02328  41.02328   0.00000  \n",
      "\n",
      "[8938 rows x 277 columns]\n",
      "openPrice     float64\n",
      "highPrice     float64\n",
      "lowPrice      float64\n",
      "closePrice    float64\n",
      "volume        float64\n",
      "               ...   \n",
      "pvos          float64\n",
      "pvoh          float64\n",
      "qqe           float64\n",
      "qqel          float64\n",
      "qqes          float64\n",
      "Length: 277, dtype: object\n"
     ]
    }
   ],
   "source": [
    "TABLES = [\"BTC_KLINES_MONTHLY_12_2020_PER_5m\"]\n",
    "\n",
    "engine = create_engine('postgresql://postgres:postgres@127.0.0.1/CryptoData')\n",
    "df = pd.DataFrame()\n",
    "for table in TABLES:\n",
    "    with engine.begin() as connection:\n",
    "        query = text(\"SELECT * FROM \\\"\" + table + \"\\\" ORDER BY \\\"ISOTimestampKlineCLOSE\\\" ASC\")\n",
    "        df1 = pd.read_sql(query, con=connection)\n",
    "\n",
    "    df = pd.concat([df, df1], axis=0, ignore_index=True)\n",
    "    print(table, len(df))\n",
    "\n",
    "\n",
    "df.drop(columns=['ISOInsertTimestamp', 'ISOTimestampKlineCLOSE', 'UNIXTimestampKlineOPEN', 'UNIXTimestampKlineCLOSE',\n",
    "                 'close_minus99_d', 'close_80_roc', 'close_99_roc', 'close_150_roc', 'mfi_80', 'mfi_99', 'mfi_150',\n",
    "                 'ftr_80', 'ftr_99', 'ftr_150','vr_6' ],\n",
    "        inplace=True)\n",
    "\n",
    "#df.drop(df.columns[56:], axis=1, inplace=True)\n",
    "print(df)\n",
    "print(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:00:29.767943104Z",
     "start_time": "2024-01-18T17:00:29.042385403Z"
    }
   },
   "id": "f79eb30ceed02cb0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18880.71    18911.46    18859.38    ...    46.81002     0.\n",
      "     46.81002]\n",
      " [18887.13    18979.99    18887.13    ...    42.14824    42.14824\n",
      "      0.     ]\n",
      " [18919.62    18940.05    18883.32    ...    42.66091    42.66091\n",
      "      0.     ]\n",
      " ...\n",
      " [29172.84    29199.      29163.69    ...    40.31081    40.31081\n",
      "      0.     ]\n",
      " [29197.93    29199.      29160.02    ...    40.54353    40.54353\n",
      "      0.     ]\n",
      " [29174.49    29202.67    29173.98    ...    41.02328    41.02328\n",
      "      0.     ]]\n",
      "[18887.13 18919.62 18892.3  ... 29197.48 29174.49 29182.99]\n",
      "std[3] 1928.5890690107578\n",
      "[[-0.61949825 -0.61538368 -0.6184909  ... -0.49676502 -0.98151441\n",
      "   0.76528564]\n",
      " [-0.61616862 -0.58000954 -0.60401848 ... -1.00446301  0.6511242\n",
      "  -0.95884825]\n",
      " [-0.59931819 -0.60062596 -0.60600551 ... -0.94862993  0.67098279\n",
      "  -0.95884825]\n",
      " ...\n",
      " [ 4.71835286  4.69488658  4.75550074 ... -1.20457101  0.57995019\n",
      "  -0.95884825]\n",
      " [ 4.73136539  4.69488658  4.75358673 ... -1.1792263   0.58896475\n",
      "  -0.95884825]\n",
      " [ 4.7192086   4.69678098  4.76086727 ... -1.12697842  0.60754817\n",
      "  -0.95884825]]\n"
     ]
    }
   ],
   "source": [
    "np_array = df.to_numpy()\n",
    "print(np_array)\n",
    "\n",
    "train_max_range = 6000\n",
    "val_max_range = train_max_range + 2000\n",
    "\n",
    "close_price = np_array[:, 3]\n",
    "print(close_price)\n",
    "\n",
    "mean = np_array[:train_max_range].mean(axis=0)\n",
    "np_array -= mean\n",
    "std = np_array[:train_max_range].std(axis=0)\n",
    "np_array /= std\n",
    "print('std[3]', std[3])\n",
    "\n",
    "print(np_array)\n",
    "\n",
    "lookback = 60\n",
    "step = 1\n",
    "delay = 1\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(np_array, lookback=lookback, delay=delay, min_index=0, max_index=train_max_range, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "val_gen = generator(np_array, lookback=lookback, delay=delay, min_index=train_max_range+1, max_index=val_max_range,\n",
    "                    shuffle=True, step=step, batch_size=batch_size)\n",
    "test_gen = generator(np_array, lookback=lookback, delay=delay, min_index=val_max_range+1, max_index=None, shuffle=True, step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (val_max_range - train_max_range - 1 - lookback) // batch_size\n",
    "test_steps = (len(np_array) - val_max_range - 1 - lookback) // batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:01:25.206630124Z",
     "start_time": "2024-01-18T17:01:25.189174059Z"
    }
   },
   "id": "9b6edca62aec7016",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6560/4238068734.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40/100 [===========>..................] - ETA: 5s - loss: 0.3463"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Dense(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mRMSprop(), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_steps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:2810\u001B[0m, in \u001B[0;36mModel.fit_generator\u001B[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[1;32m   2798\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001B[39;00m\n\u001B[1;32m   2799\u001B[0m \n\u001B[1;32m   2800\u001B[0m \u001B[38;5;124;03mDEPRECATED:\u001B[39;00m\n\u001B[1;32m   2801\u001B[0m \u001B[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001B[39;00m\n\u001B[1;32m   2802\u001B[0m \u001B[38;5;124;03m  use this endpoint.\u001B[39;00m\n\u001B[1;32m   2803\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2804\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2805\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Model.fit_generator` is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2806\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future version. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2807\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease use `Model.fit`, which supports generators.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2808\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   2809\u001B[0m )\n\u001B[0;32m-> 2810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2811\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2812\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2815\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2817\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2818\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2819\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2820\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2821\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2822\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2824\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2825\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1740\u001B[0m ):\n\u001B[1;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    146\u001B[0m   (concrete_function,\n\u001B[1;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs)\u001B[0m\n\u001B[1;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1351\u001B[0m     args,\n\u001B[1;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1353\u001B[0m     executing_eagerly)\n\u001B[1;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1472\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(256,\n",
    "              dropout=0.1, recurrent_dropout=0.5, return_sequences=True, input_shape=(None, np_array.shape[-1])))\n",
    "model.add(GRU(512, activation='relu', dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n",
    "                              validation_data=val_gen, validation_steps=val_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:41:54.764051514Z",
     "start_time": "2024-01-18T17:41:49.081253145Z"
    }
   },
   "id": "2d50cefa18f6736",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6560/3870388050.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/100 [==>...........................] - ETA: 7s - loss: 0.2734"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Dense(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mRMSprop(), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_steps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:2810\u001B[0m, in \u001B[0;36mModel.fit_generator\u001B[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[1;32m   2798\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001B[39;00m\n\u001B[1;32m   2799\u001B[0m \n\u001B[1;32m   2800\u001B[0m \u001B[38;5;124;03mDEPRECATED:\u001B[39;00m\n\u001B[1;32m   2801\u001B[0m \u001B[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001B[39;00m\n\u001B[1;32m   2802\u001B[0m \u001B[38;5;124;03m  use this endpoint.\u001B[39;00m\n\u001B[1;32m   2803\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2804\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2805\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Model.fit_generator` is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2806\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future version. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2807\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease use `Model.fit`, which supports generators.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2808\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   2809\u001B[0m )\n\u001B[0;32m-> 2810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2811\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2812\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2815\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2817\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2818\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2819\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2820\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2821\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2822\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2824\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2825\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1740\u001B[0m ):\n\u001B[1;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    146\u001B[0m   (concrete_function,\n\u001B[1;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs)\u001B[0m\n\u001B[1;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1351\u001B[0m     args,\n\u001B[1;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1353\u001B[0m     executing_eagerly)\n\u001B[1;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1472\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(32,\n",
    "              dropout=0.1, recurrent_dropout=0.5, return_sequences=True, input_shape=(None, np_array.shape[-1])))\n",
    "model.add(GRU(64, activation='relu', dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n",
    "                              validation_data=val_gen, validation_steps=val_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:42:03.484931223Z",
     "start_time": "2024-01-18T17:42:00.571051592Z"
    }
   },
   "id": "52802e6afb9a4aab",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmarcinski\\AppData\\Local\\Temp\\ipykernel_9528\\2815929554.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 35s 231ms/step - loss: 0.2011 - val_loss: 1.0162\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.1272 - val_loss: 1.1430\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.1030 - val_loss: 1.1502\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.0893 - val_loss: 1.1150\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0814 - val_loss: 1.0350\n"
     ]
    }
   ],
   "source": [
    "#big_np = tf.expand_dims(np_array, axis=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 5, activation='relu', input_shape=(None, np_array.shape[-1])))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(32, 5, activation='relu'))\n",
    "\n",
    "# LSTM layers\n",
    "model.add(GRU(32, dropout=0.1, recurrent_dropout=0.5, return_sequences=True))\n",
    "model.add(GRU(64, dropout=0.1, recurrent_dropout=0.5,))\n",
    "\n",
    "#Final layers\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5,\n",
    "                              validation_data=val_gen, validation_steps=val_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:03:51.461552Z",
     "start_time": "2024-01-18T11:01:33.556194300Z"
    }
   },
   "id": "32ff50c842819669",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T10:13:25.581742600Z",
     "start_time": "2024-01-18T10:13:25.567452900Z"
    }
   },
   "id": "805ebfdd8c5227e",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVvUlEQVR4nO3deVhUZf8/8PeAMKAIorJL4L6h4h4ooIniN8O9TEsRcyltMR8rrRTNikozNzI1gx7NXNGnxdxQ3FcUNUXccClZFBUQFXTm/v1x/xgdWZxB4DDwfl3XXHUO9znzOXNmnM/cq0oIIUBERESkEDOlAyAiIqLKjckIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgRVQhRUVFQqVS4dOlSuTxfcXXp0gVdunTRbV+6dAkqlQpRUVFPPXb48OHw9PQsl7ERPY7JCJmkkydPYuDAgfDw8ICVlRXc3NzQvXt3zJ8/X6/cl19+iQ0bNpRKDPv27cO0adNw+/btEj3vxo0bMW3atBI9JxFReabi2jRkavbt24euXbviueeeQ0hICJydnXH16lUcOHAAFy5cwPnz53VlbWxsMHDgwFL5pTZr1ix88MEHSEpKKtFfn2+//TYiIiLAj6ZxNBoNHjx4ALVaDZVKVe7OV1x5NQ+xsbEAACEEcnJyYGFhAXNz8yKPHT58OGJjY0utdic3NxcAYGlpaXRsRI+ronQARMb64osvYGdnh8OHD6NGjRp6f0tLSyv2ebOzs1GtWrVnjK5sPXz4EFqtVvdlUJmZm5uX6BdgSZ+vpKhUKlhZWSkdBgDke9+Vp9jItLCZhkzOhQsX0Lx583yJCAA4Ojrq/l+lUiE7Oxs///wzVCoVVCoVhg8fDgCYNm0aVCoVTp8+jSFDhsDe3h6dO3cGAJw4cQLDhw9HvXr1YGVlBWdnZ4wYMQLp6em6c0+bNg0ffPABAKBu3bq68+f9Ao2MjMQLL7wAR0dHqNVqNGvWDAsXLnzqtQ0fPhwRERG6+PMewKP2+FmzZmHOnDmoX78+1Go1Tp8+DQA4c+YMBg4ciJo1a8LKygrt2rXDb7/9pnf+vH4Qe/fuxYQJE+Dg4IBq1aqhX79+uH79er54vv/+ezRv3hxqtRqurq4YN26cXrPUvHnzYG5urrfv22+/hUqlwoQJE3T7NBoNqlevjo8++ki3b9asWfD19UWtWrVgbW2Ntm3bYu3atfliUKlUePvtt7FhwwZ4eXlBrVajefPm2LRpU4HX9ngtwP/+9z/06tULrq6uUKvVqF+/PmbMmAGNRvOUO2FYn5HffvsNKpUKJ06c0O1bt24dVCoV+vfvr1e2adOmGDRokG67uO+Rwvpl5L0+VlZW8PLywvr16ws83tDXHQCWL1+ODh06oGrVqrC3t4e/vz+2bNmi+zv7jFBJYc0ImRwPDw/s378ff//9N7y8vAott2zZMowcORIdOnTA6NGjAQD169fXK/Pyyy+jYcOG+PLLL3XNIlu3bsXFixcRGhoKZ2dnnDp1CosXL8apU6dw4MAB3RfN2bNn8euvv+K7775D7dq1AQAODg4AgIULF6J58+bo3bs3qlSpgt9//x1jx46FVqvFuHHjCo15zJgxuHbtGrZu3Yply5YVWCYyMhL379/H6NGjoVarUbNmTZw6dQqdOnWCm5sbJk2ahGrVqmH16tXo27cv1q1bh379+umd45133oG9vT3CwsJw6dIlzJkzB2+//TZWrVqlKzNt2jRMnz4dgYGBeOutt5CYmIiFCxfi8OHD2Lt3LywsLODn5wetVos9e/bgpZdeAgDs3r0bZmZm2L17t+5cx44dw507d+Dv76/bN3fuXPTu3RuvvfYacnNzsXLlSrz88sv4448/0KtXL7149+zZg+joaIwdOxbVq1fHvHnzMGDAAFy5cgW1atUq9PWMioqCjY0NJkyYABsbG2zfvh1Tp05FZmYmZs6cWehxhurcuTNUKhV27dqFli1b6l3/nj17dOWuX7+OM2fO4O2339btK+57pCBbtmzBgAED0KxZM4SHhyM9PR2hoaGoU6dOvrKGvu7Tp0/HtGnT4Ovri88++wyWlpY4ePAgtm/fjh49ehj7UhEVTRCZmC1btghzc3Nhbm4ufHx8xIcffig2b94scnNz85WtVq2aCAkJybc/LCxMABCDBw/O97e7d+/m2/frr78KAGLXrl26fTNnzhQARFJSkkHnCAoKEvXq1XvK1Qkxbtw4UdBHMykpSQAQtra2Ii0tTe9v3bp1Ey1atBD379/X7dNqtcLX11c0bNhQty8yMlIAEIGBgUKr1er2v//++8Lc3Fzcvn1bCCFEWlqasLS0FD169BAajUZXbsGCBQKA+Omnn4QQQmg0GmFrays+/PBD3XPWqlVLvPzyy8Lc3FxkZWUJIYSYPXu2MDMzE7du3Sr0NcrNzRVeXl7ihRde0NsPQFhaWorz58/r9h0/flwAEPPnz893bY/fj4Luw5gxY0TVqlX1XquCFHS+gjRv3ly88soruu02bdqIl19+WQAQCQkJQgghoqOjBQBx/PjxImMr6D0SEBAgAgICdNt574PIyEjdPm9vb+Hi4qK7f0LIzwkA4eHhoXc+Q173c+fOCTMzM9GvXz+9+y+E0HvfGBIbkSHYTEMmp3v37ti/fz969+6N48eP45tvvkFQUBDc3NzyNUs8zZtvvplvn7W1te7/79+/jxs3buD5558HABw9etSg8z5+joyMDNy4cQMBAQG4ePEiMjIyjIrxSQMGDNDVwADAzZs3sX37drzyyivIysrCjRs3cOPGDaSnpyMoKAjnzp3Dv//+q3eO0aNH63XK9PPzg0ajweXLlwEA27ZtQ25uLsaPHw8zs0f/TIwaNQq2trb4888/AQBmZmbw9fXFrl27AAAJCQlIT0/HpEmTIITA/v37AcjaAi8vL72mtcdfo1u3biEjIwN+fn4FvsaBgYF6tVotW7aEra0tLl68WORr9fhz5L02fn5+uHv3Ls6cOVPksYby8/PT1QJlZWXh+PHjGD16NGrXrq3bv3v3btSoUUOvJq+k3iPJycmIj49HSEgI7OzsdPu7d++OZs2a5StvyOu+YcMGaLVaTJ06Ve/+A1C0My9VXExGyCS1b98e0dHRuHXrFg4dOoTJkycjKysLAwcO1PWhMETdunXz7bt58ybee+89ODk5wdraGg4ODrpyhn5J7N27F4GBgahWrRpq1KgBBwcHfPzxx0adw9CYz58/DyEEpkyZAgcHB71HWFgYgPwde5977jm9bXt7ewDyywmALilp3LixXjlLS0vUq1dP93dAfhnHxcXh3r172L17N1xcXNCmTRu0atVK92W8Z88e+Pn56Z3rjz/+wPPPPw8rKyvUrFkTDg4OWLhwYYGvz5Px5sWcF29hTp06hX79+sHOzg62trZwcHDA66+/DuDZ70MePz8/JCcn4/z589i3bx9UKhV8fHz0kpTdu3ejU6dOel/sJfUeybsXDRs2zPe3J+8fYNjrfuHCBZiZmRWYzBCVBvYZIZNmaWmJ9u3bo3379mjUqBFCQ0OxZs0a3Zfw0zz+KzHPK6+8gn379uGDDz6At7c3bGxsoNVq0bNnT2i12qee88KFC+jWrRuaNGmC2bNnw93dHZaWlti4cSO+++47g85hTMx555s4cSKCgoIKPKZBgwZ624WNEhHFGE7cuXNnPHjwAPv378fu3bt1SUfel/GZM2dw/fp1vWRk9+7d6N27N/z9/fH999/DxcUFFhYWiIyMxIoVK/I9R3HivX37NgICAmBra4vPPvsM9evXh5WVFY4ePYqPPvrome9DnryOz7t27cLFixfRpk0bVKtWDX5+fpg3bx7u3LmDY8eO4YsvvtAdU9rvkcIY+7oTlRUmI1RhtGvXDoCsts5jbJXyrVu3EBMTg+nTp2Pq1Km6/efOnctXtrBz//7778jJycFvv/2m94t+x44dBsVgbMz16tUDAFhYWCAwMNCoYwvj4eEBAEhMTNSdH5DzSiQlJek9T4cOHWBpaYndu3dj9+7dulFG/v7+WLJkCWJiYnTbedatWwcrKyts3rwZarVatz8yMrJE4gfkvBzp6emIjo7We+6kpKQSew5A1to899xz2L17Ny5evKhLuvz9/TFhwgSsWbMGGo1GL4ZnfY88Lu9eFfQeTUxM1Ns29HWvX78+tFotTp8+DW9vb6NjIjIWm2nI5OzYsaPAX8QbN24EoF81Xa1aNaNmSM37Bf7k+efMmZOvbN6cJE+ev6BzZGRkGPxFW9h5C+Po6IguXbpg0aJFeolYnoKG7D5NYGAgLC0tMW/ePL3rWLp0KTIyMvRGXVhZWaF9+/b49ddfceXKFb2akXv37mHevHmoX78+XFxcdMeYm5tDpVLpDbG9dOlSic6WW9B9yM3Nxffff19iz5HHz88P27dvx6FDh3TX7+3tjerVq+Orr77SDaEtKjZj3iOPc3Fxgbe3N37++We9ppatW7fma7I09HXv27cvzMzM8Nlnn+WrpSlO7RnR07BmhEzOO++8g7t376Jfv35o0qQJcnNzsW/fPqxatQqenp4IDQ3VlW3bti22bduG2bNnw9XVFXXr1kXHjh0LPbetrS38/f3xzTff4MGDB3Bzc8OWLVsK/DWd9+XyySef4NVXX4WFhQWCg4PRo0cPWFpaIjg4GGPGjMGdO3ewZMkSODo6FpgsFHbed999F0FBQTA3N8err75a5DERERHo3LkzWrRogVGjRqFevXpITU3F/v378c8//+D48eNPfd7HOTg4YPLkyZg+fTp69uyJ3r17IzExEd9//z3at2+v63eRx8/PD1999RXs7OzQokULADJJaty4MRITE3Xzu+Tp1asXZs+ejZ49e2LIkCFIS0tDREQEGjRooDdnx7Pw9fWFvb09QkJC8O6770KlUmHZsmWl8mXq5+eHX375BSqVStdsY25uDl9fX2zevBldunTRmyDsWd8jTwoPD0evXr3QuXNnjBgxAjdv3sT8+fPRvHlz3LlzR1fO0Ne9QYMG+OSTTzBjxgz4+fmhf//+UKvVOHz4MFxdXREeHv4MrxZRAZQZxENUfH/99ZcYMWKEaNKkibCxsRGWlpaiQYMG4p133hGpqal6Zc+cOSP8/f2FtbW1AKAb5ps3tPf69ev5zv/PP/+Ifv36iRo1agg7Ozvx8ssvi2vXrgkAIiwsTK/sjBkzhJubmzAzM9MbBvrbb7+Jli1bCisrK+Hp6Sm+/vpr8dNPPxk0VPThw4finXfeEQ4ODkKlUumG+eYNm5w5c2aBx124cEEMGzZMODs7CwsLC+Hm5iZeeuklsXbtWl2ZvOGqhw8f1jt2x44dAoDYsWOH3v4FCxaIJk2aCAsLC+Hk5CTeeustveG5ef78808BQPzf//2f3v6RI0cKAGLp0qX5jlm6dKlo2LChUKvVokmTJiIyMlJ3Xx4HQIwbNy7f8R4eHnrDtgsairt3717x/PPPC2tra+Hq6qobBl7QtT7J0KG9Qghx6tQpAUA0bdpUb//nn38uAIgpU6bkO8bQ94ihw2fXrVsnmjZtKtRqtWjWrJmIjo4WISEh+Yb2Gvq6CyHETz/9JFq3bi3UarWwt7cXAQEBYuvWrUbHRvQ0XJuGiIiKxc/PD2q1Gtu2bVM6FDJx7DNCRETFkpycrJt9mOhZMBkhIiKj7Nu3DxMnTtQNUSZ6VmymISIio4SGhuKvv/7C4MGDMXPmTFSpwrEQ9GyYjBAREZGi2ExDREREimIyQkRERIoyiYY+rVaLa9euoXr16lwxkoiIyEQIIZCVlQVXV9d8K0A/ziSSkWvXrsHd3V3pMIiIiKgYrl69ijp16hT6d5NIRqpXrw5AXoytra3C0RAREZEhMjMz4e7urvseL4xJJCN5TTO2trZMRoiIiEzM07pYsAMrERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgREREpyuhkZNeuXQgODoarqytUKhU2bNhQZPno6Gh0794dDg4OsLW1hY+PDzZv3lzceEvUX38BAwYA2dlKR0JERFR5GZ2MZGdno1WrVoiIiDCo/K5du9C9e3ds3LgRcXFx6Nq1K4KDg3Hs2DGjgy1J2dnAsGFAdDQQEAAkJysaDhERUaWlEkKIYh+sUmH9+vXo27evUcc1b94cgwYNwtSpUw0qn5mZCTs7O2RkZMDW1rYYkRZs716gTx8gPR1wdwf+/BNo0aLETk9ERFSpGfr9XeZ9RrRaLbKyslCzZs1Cy+Tk5CAzM1PvURo6dQIOHAAaNQKuXpXbW7aUylMRERFRIco8GZk1axbu3LmDV155pdAy4eHhsLOz0z3c3d1LLZ4GDYD9+wF/fyArC3jxRWDJklJ7OiIiInpCmSYjK1aswPTp07F69Wo4OjoWWm7y5MnIyMjQPa5evVqqcdWsKWtEXn8d0GiA0aOBjz4CtNpSfVoiIiJCGSYjK1euxMiRI7F69WoEBgYWWVatVsPW1lbvUdrUauC//wWmTZPb33wDDBoE3LtX6k9NRERUqZVJMvLrr78iNDQUv/76K3r16lUWT1ksKhUQFiaTEgsLYO1aoGtXIC1N6ciIiIgqLqOTkTt37iA+Ph7x8fEAgKSkJMTHx+PKlSsAZBPLsGHDdOVXrFiBYcOG4dtvv0XHjh2RkpKClJQUZGRklMwVlIKhQ4GtWwF7e+DgQeD554GEBKWjIiIiqpiMTkaOHDmC1q1bo3Xr1gCACRMmoHXr1rphusnJybrEBAAWL16Mhw8fYty4cXBxcdE93nvvvRK6hNIRECA7ttarByQlAb6+wI4dSkdFRERU8TzTPCNlpbTmGTHE9etA377Avn1AlSpypM3w4WUaAhERkUkqt/OMmBoHByAmRnZmffgQCA0FpkwByn8KR0REZBqYjBjAygpYsQL4+GO5/fnnchjw/fvKxkVERFQRMBkxkJkZ8MUXwNKlsrlmxQqge3fgxg2lIyMiIjJtTEaMNGKEXO3X1hbYswfw8QHOnVM6KiIiItPFZKQYAgNlh1YPD+D8eTn0d/dupaMiIiIyTUxGiql5czkHSfv2wM2bMkFZsULpqIiIiEwPk5Fn4OQExMYC/foBubnAa68BM2ZwpA0REZExmIw8o6pV5bTxEyfK7alT5fDf3Fxl4yIiIjIVTEZKgJkZMHMmsHAhYG4O/PwzEBQE3LqldGRERETlH5OREvTmm8AffwA2NrL5xtcXuHhR6aiIiIjKNyYjJaxnTznkt04d4MwZOdLmwAGloyIiIiq/mIyUglat5Eib1q3l2jZduwJr1igdFRERUfnEZKSUuLoCu3YBL70kp41/5RXg66850oaIiOhJTEZKkY0NsGED8M47cnvSJGDMGODBA0XDIiIiKleYjJQyc3Ng3jxg7lw56mbJEqBXLyAjQ+nIiIiIygcmI2Xk3XdlLUnVqsDWrUCnTsDly0pHRUREpDwmI2UoOFj2I3FxAU6dkiNtjhxROioiIiJlMRkpY23bypE2LVoAKSmAv7+sMSEiIqqsqigdQGXk7i7nInnlFWDzZqB/f+Dbb4Hx4wGVSunoiMqGEDIR/+ILOVuxhQVgaSn/+/jjyX3Gbpf0OfgZJSp5TEYUYmsrZ2t9+21g0SJgwgTgwgVgzhygCu8KVXAXLshRZn/9pXQkxjM3VyYJKsljmFBRecOvPQVVqSLXs2nQAPjwQyAiAkhKAlauBKpXVzo6opJ3/z7w1VfykZMjvyQ/+ECOMHvwQP+Rm/ts2yV1jidpNPJx/37Zv34lpUqVkk2CbGzknEr+/nLUIJGxVEKU/2m4MjMzYWdnh4yMDNja2iodTqlYtw54/XX5D1yrVrLWpE4dpaMiKjkbN8rakLz1mrp3BxYsABo1UjauoggBPHxYuglPaZ/z4cOye73q1gVCQuTD07PsnpfKL0O/v5mMlCMHDwK9ewNpaXIG1z//BLy9lY6K6NlcuSL7Q61fL7fd3IDvvgMGDmRzQVnIS6hKM2m6fFkueZGV9eh5u3YFQkNln7hq1ZS7flIWkxETdekS8OKLQEKC/ACvWiWrsIlMTW4uMHs2MGMGcPeu7Gvx/vvA1KlshqyI7t6VCWdkJLB9+6OlL6pXl531hw+X8ysxAa1cmIyYsNu3gQED5AfazEzO4DpunNJRERlu+3b5nj1zRm77+QHffw94eSkbF5WNy5eBZcuAqCjZWTlPgwYyKRk2TI4qpIrP0O9vdjUqh2rUkKMMQkMBrVaOuJkwQXaaIyrPkpOBIUOAbt1kIuLoCPz3v8DOnUxEKhMPD+DTT4Fz5+REj6Ghsqb3/Hm538MD6NEDWLECuHdP6WipPGAyUk5ZWgJLl8o5GADZxj5gAJCdrWxcRAV5+FAOS2/cGPj1V1mj9/bbQGIiMHQoq+YrK5VK1or99JOc5DEqCujSRTbhbN0KvPYa4OwsFxA9cICrmldmbKYxAatWyd7pOTlAu3bA77/LDzBRebB3LzB2LHDihNzu2FE2ybRpo2xcVH5dvChrzKKi9NfoatJENuMMHSo78ZPpY5+RCmbvXqBPHyA9HXjuOTnShtXepKS0NOCjj+QXCgDUrCnnD3njDc41QYbRamUTXmQksHbtoyYbMzMgKEgmJr17A1ZWioZJz4DJSAV0/rwcWXP2rJzBdc0a2e5KVJY0GmDxYuDjj2VnawAYORIIDwdq11Y0NDJhmZny37SoKLlcRh57e2DwYNnvpG1bNvmZGiYjFdTNm0C/frJTmLm5nMF11Cilo6LK4sgR4K23Hq023bq1bJJ5/nll46KK5dw54Oef5eOffx7tb95cJiV5fU2o/ONomgqqZk1gyxY5W6tGA4weDUyaJKs7iUrLzZsyCenQQSYitrbA/PnA4cNMRKjkNWwIfP65nHdpyxY5QsvKCjh1Cpg4Uc5O3bs3EB0t57Mh08eaERMlBPDZZ8C0aXL75Zflrwhra0XDogpGq5Xvqw8/BG7ckPtefx2YOZO/TKls3b4NrF4t+5ccOPBof61asqZk+HBZU0flC5tpKolly2SHwQcP5C/U//1Pzu1A9KyOH5cTl+3dK7ebNZNNMgEBysZFdOaM7Fvy3//KuW3ytGolk5LXXgMcHJSKjh7HZKQS2blT9iO5dUsuVPXnn0DTpkpHRaYqMxMIC5PNMBqNnKxq2jTgvffkCq1E5cXDh3K+kqgoYMOGR002VarIVYRDQ4H/+z++b5XEZKSSSUyUa9pcvChncI2OlgtVERlKCGDlSuA//3n0a/Pll+X6MlxBmsq7mzfl+zcy8lEHa0DWFL/+uqwxadFCsfAqLSYjldD160DfvsC+ffKXwJIlcrI0oqdJSJBNMjt2yO2GDYEFCzh0nEzT33/L2pJly+R8OHnatpVJyZAhcjAAlT6OpqmEHByAmBhg0CDZh2T4cLlCavlPN0kp2dlyNFarVjIRsbKSq+yePMlEhEyXlxcwa5YcFvz770D//vIHWlwc8M47gIuLrPXbuFE29ZDyWDNSAWm1wJQpwJdfyu0hQ+TaEGq1snFR+SGEbGMfPx64ckXuCw4G5s6V/Y6IKpobN+TCfFFRwLFjj/Y7O8vp50ND2deuNLCZhvDTT3IBqocPgc6d5ZdPrVpKR0VKu3BB/jr86y+57ekJzJsnkxGiyuD4cZmULF/+aMg6IOfRCQ0FXn1V9r2jZ8dkhAAA27bJ1X4zM2U/gD//lP+lyufePeDrr+X6MTk5cmXoDz8EJk8GqlZVOjqispebK5tqIiPlv40ajdyvVssRisOHA4GBcrZrKh4mI6Rz6pRc0+byZdlp63//kzUlVHls3ChrQy5elNvdu8sOqo0aKRsXUXmRmgr88otMTP7++9F+Nzdg2DCZmPDzYjwmI6QnNVVWwx8+LH8RR0XJxaeoYrtyRfYLWb9ebru5Ad99BwwcyAXHiAoiBHD0qPw3csUKOWQ4j6+vbMZ55RW5JAI9HUfTkB4nJyA2VlY95ubKTq2ff86RNhVVbq5sjmnaVCYi5uZyTY+EBDmKgIkIUcFUKjkEeP584No1uZJwr16AmZmcNmHUqEedXmNiuC5YSWHNSCWj1QIffSSHvQGy6nHRIllbQhXD9u1yzpAzZ+S2vz8QESGHOxJR8SQnyw6vkZEyqc/z3HNyPqeQEKB+feXiK6/YTENF+uEH4O23ZYetrl2BdesAe3ulo6Jnce2anD115Uq57egok87XX2dNCFFJEUI2d0dGAr/+CmRkPPqbv7/8gffyy4CNjWIhlitMRuipNm2SH5o7d4AmTWRv8nr1lI6KjPXwoeyMOnUqkJUlq5PHjpWTl3F4IlHpuXdPDgiIigK2bHnU7F2tmuyXFRoK+PnJz2RlxWSEDHL8uFxQ6p9/5Ayuv/0mV/8l07B3r0w8TpyQ2x07ypV127RRNi6iyuaff+T085GRwLlzj/bXrStrS4YNk3P6VDal1oF1165dCA4OhqurK1QqFTZs2PDUY2JjY9GmTRuo1Wo0aNAAUVFRxj4tlZJWrYCDB4HWreXaNl27AmvXKh0VPU1amvzV1bmzTERq1gQWL5Yd7JiIEJW9OnXknD2JifJHwsiRQPXqQFKSXAW7bl2gWzeZsNy9q3S05Y/RyUh2djZatWqFiIgIg8onJSWhV69e6Nq1K+Lj4zF+/HiMHDkSmzdvNjpYKh2ursCuXbKG5P592XTzzTccaVMeaTTAwoVA48ayahiQ/+glJspe/pW5OpioPFCp5BDgJUuAlBSZfHTrJvdv3y5rSJyd5ed2717+O5vnmZppVCoV1q9fj759+xZa5qOPPsKff/6Jvx+bRebVV1/F7du3sWnTJoOeh800ZUOjAd5/Xw5pA4DRo2VfBAsLZeMi6fBh2SSTtzx669aySYbNakTl3+XLwH//K39E5E0+CAANGjxqxnF3Vyq60lNu5hnZv38/AgMD9fYFBQVh//79hR6Tk5ODzMxMvQeVPnNzuUbJ3LnyF/bixbK25PHe4lT2bt4E3npL9gc5cgSws5MJ4+HDTESITIWHh1zA9Px5YOdO2cxarZrc/vRT+fcePeQInXv3lI627JV6MpKSkgInJye9fU5OTsjMzMS9Ql7x8PBw2NnZ6R7uFTFdLMfefVcuqle1quwh3rnzo5VdqexotbIzXOPGcii2EHKipcREOSyb62UQmR6VSg4B/ukn2YwTFQUEBMjP99atckJKFxfgzTeBAwcqTzNOuWxhnjx5MjIyMnSPq1evKh1SpRMcLPuRuLjIdRo6dgTi4pSOqvI4flwOCRwxQq4q2ry5nEH3v/+Vs+kSkemzsZGTpcXGytW0p06VNSQZGXIySh8foFkzucDltWtKR1u6Sj0ZcXZ2Rmpqqt6+1NRU2NrawtrausBj1Go1bG1t9R5U9tq2lSNtWrSQGby/vxxTT6UnM1P222nbVo6MqVYNmDkTOHZM/noiooqpXj1g+nTZnyQmRtaCWlvLmZQnTZL9SV58UU5Pn5OjdLQlr9STER8fH8TExOjt27p1K3x8fEr7qakEuLsDe/YAQUFyOFq/fsCcOZWn6rCsCCHbips0ka+vRiNHNZ05I9eUYSdiosrBzAx44QVZC5qSAvz4o2wq12qBv/6Si/S5uMim2iNHKs6/xUYnI3fu3EF8fDzi4+MByKG78fHxuPL/OxVMnjwZw4YN05V/8803cfHiRXz44Yc4c+YMvv/+e6xevRrvv/9+yVwBlTpbW+CPP4AxY+Qb//33Zb+Shw+VjqxiSEiQQ/+GDJHrXzRsCGzeDKxeLecuIKLKydYWeOMNYPdu4OxZ4JNP5L8Jt27J9abatwdatgS+/VauzG7ShJF27NghAOR7hISECCGECAkJEQEBAfmO8fb2FpaWlqJevXoiMjLSqOfMyMgQAERGRoax4VIJ0mqFmDlTCJVKCECIXr2EyMpSOirTdeeOEB99JISFhXw9rayEmDFDiPv3lY6MiMqrhw+F2LxZiMGD5b8Z8ieiEObmQgQHCxEdLUROjtJRPmLo9zengyejrVsnF1+7fx/w9pa1Jm5uSkdlOoQA1q8Hxo8H8vpmBwfLIdV16yoaGhGZkNu3gVWr5IicAwce7a9dG3jtNTl/ibe3MrHl4do0VKoOHgR695bTkru5yUX2WrVSOqry7/x52cT1119y29NTzu0SHKxoWERk4hISgJ9/ln1NkpMf7W/VSs5pMmSIXH+srDEZoVJ36ZLs3Z2QIIeorVoltym/e/fk8LyvvpI94S0tgQ8/lGtZVK2qdHREVFE8fCjnK4mMlKMfc3PlfgsLOYnl8OHA//1f2XWKZzJCZeL2bWDAALnmgpmZnBl07FiloypfNm4E3nnn0RTQ3bvLafYbNVI2LiKq2G7elKP0oqIeLSMBAI6Osqk9NBTw8irdGMrNdPBUsdWoIZscQkPl0LNx44D//EcOTa3sLl+WQ6F79ZKJiJubHCGzeTMTESIqfTVryn+TDx8GTp6U/zY7Osrm9dmz5RxS7drJkTk3byobK2tGqEQIAYSHy6FnANC3L7B8uZy0q7LJzZUf9M8+k80zVarIzqpTp8olxYmIlPLgAbBpk2zG+f33R1M0WFrKpvYi1r0tFjbTkCJWrZLTG+fkyIz799/lctmVxfbt8pfImTNy299frqzbvLmycRERPen6dWDFCtmMc+IE8M8/ckK1ksRkhBSzdy/Qpw+Qng4895wcaVPa7ZJKu3ZNVoGuXCm3HR2BWbNku6xKpWxsRERPc/GinJK+pLHPCCmmUyc55r1RI7nab6dOsnd3RfTwoZy+vUkTmYiYmclpmhMT5doSTESIyBSURiJiDCYjVCoaNAD275fNFJmZcijZjz8qHVXJ2rtXLmj3/vtAVpZc2fjwYTmiqEYNpaMjIjIdTEao1NSsCWzZIpsqNBpg1Cg5r4ZWq3RkzyYtTY4e6txZtrPWrAksWSJX2W3TRunoiIhMD5MRKlVqtZwRcNo0uf3VV8Crr8pRJqZGowEWLgQaN5YdvgBg5EjZJDNypGyiISIi4/GfTyp1KhUQFiaTEgsLYM0auUR2WprSkRnu8GHg+eflhG63bwOtW8tmqCVL5DoQRERUfExGqMwMHSo7strbyw6uzz//aAhseXXzJvDmm7I/yJEjgJ2d7BOSl5wQEdGzYzJCZSogQNYo1KsHJCUBPj5AbKzSUeWn1cpJgRo3BhYtkpO6DR0qm2TefhswN1c6QiKiioPJCJW5xo1lzYivr2zy6NFDrjZZXhw/Dvj5ASNGADduyAnLYmNlM5OTk9LRERFVPExGSBEODkBMDDBokJyeePhw2a9EySn4MjPltO1t28qRMdWqATNnAseOyRodIiIqHUxGSDFWVnIq4o8/ltuffSaHAefklG0cQsiVLRs3BubOlaNmXn5Z9meZOLHsltomIqqsmIyQoszMgC++AJYulQvKrVgBdO8up5IvCwkJQLduwJAhQEoK0LChXFV39WqgTp2yiYGIqLJjMkLlwogRwF9/Aba2wO7dsmPr+fOl93zZ2cCkSUDLlsCOHbKW5vPP5TLbPXqU3vMSEVF+TEao3AgMlH01PDyAc+fk0Nk9e0r2OYQAoqOBpk2Br7+Wa8sEBwOnTwOffCInaSMiorLFZITKlebNgYMHgfbtZVNNt26yP0dJOH8e6NULGDAAuHoV8PQEfvtNPurWLZnnICIi4zEZoXLHyUkOpe3XD8jNlf05vvii+CNt7t2T09F7ecmmIEtL4NNPgVOnZK0IEREpi8kIlUtVqwJr18rRLIBMHkaMkMmJMTZulEnI9OlylE6PHrJfyIwZ8jmIiEh5TEao3DIzk/N8LFwoZzyNigJ69gRu3Xr6sZcvy5qVXr2AixcBNzc5QmbTJqBRo1IPnYiIjMBkhMq9N98E/vgDsLGRI198feVU8gXJzQXCw2UH1Q0b5HDhiRPlEN6XX5aL9hERUfnCZIRMQs+ecmRNnTpyMrKOHeWU8o+LiZFDdT/+WPYT8fcH4uNl7Ur16oqETUREBmAyQiajVSs50qZ1a+D6daBrV9mv5No1YPBgOTQ4MRFwdJTryMTGytE5RERUvlVROgAiY7i6Art2yeTjjz9k00u1anISMzMzYOxY2Tm1Rg2lIyUiIkOxZoRMjo2N7A/yzjtyOztbNtscPgzMn89EhIjI1LBmhEySuTkwb55cTffhQ1lDYsbUmojIJDEZIZM2YIDSERAR0bPib0kiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUlSxkpGIiAh4enrCysoKHTt2xKFDh4osP2fOHDRu3BjW1tZwd3fH+++/j/v37xcrYCIiIqpYjE5GVq1ahQkTJiAsLAxHjx5Fq1atEBQUhLS0tALLr1ixApMmTUJYWBgSEhKwdOlSrFq1Ch9//PEzB09ERESmz+hkZPbs2Rg1ahRCQ0PRrFkz/PDDD6hatSp++umnAsvv27cPnTp1wpAhQ+Dp6YkePXpg8ODBT61NISIiosrBqGQkNzcXcXFxCAwMfHQCMzMEBgZi//79BR7j6+uLuLg4XfJx8eJFbNy4ES+++GKhz5OTk4PMzEy9BxEREVVMVYwpfOPGDWg0Gjg5Oentd3JywpkzZwo8ZsiQIbhx4wY6d+4MIQQePnyIN998s8hmmvDwcEyfPt2Y0IiIiMhElfpomtjYWHz55Zf4/vvvcfToUURHR+PPP//EjBkzCj1m8uTJyMjI0D2uXr1a2mESERGRQoyqGalduzbMzc2Rmpqqtz81NRXOzs4FHjNlyhQMHToUI0eOBAC0aNEC2dnZGD16ND755BOYmeXPh9RqNdRqtTGhERERkYkyqmbE0tISbdu2RUxMjG6fVqtFTEwMfHx8Cjzm7t27+RIOc3NzAIAQwth4iYiIqIIxqmYEACZMmICQkBC0a9cOHTp0wJw5c5CdnY3Q0FAAwLBhw+Dm5obw8HAAQHBwMGbPno3WrVujY8eOOH/+PKZMmYLg4GBdUkJERESVl9HJyKBBg3D9+nVMnToVKSkp8Pb2xqZNm3SdWq9cuaJXE/Lpp59CpVLh008/xb///gsHBwcEBwfjiy++KLmrICIiIpOlEibQVpKZmQk7OztkZGTA1tZW6XCIiIjIAIZ+f3NtGiIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlJUFaUDICKiR7RaLXJzc5UOg8ggFhYWMDc3f+bzMBkhIioncnNzkZSUBK1Wq3QoRAarUaMGnJ2doVKpin0OJiNEROWAEALJyckwNzeHu7s7zMzYik7lmxACd+/eRVpaGgDAxcWl2OdiMkJEVA48fPgQd+/ehaurK6pWrap0OEQGsba2BgCkpaXB0dGx2E02TL2JiMoBjUYDALC0tFQ4EiLj5CXPDx48KPY5mIwQEZUjz9LuTqSEknjPMhkhIiIiRTEZISIiIkUxGSEiqkA0GiA2Fvj1V/nf/98VhahAly5dgkqlQnx8vKJxMBkhIqogoqMBT0+ga1dgyBD5X09Pub+0XL9+HW+99Raee+45qNVqODs7IygoCHv37tWVUalU2LBhQ4k8X0l+eQ4fPhx9+/Z95vOYMnd3dyQnJ8PLy0vRODi0l4ioAoiOBgYOBITQ3//vv3L/2rVA//4l/7wDBgxAbm4ufv75Z9SrVw+pqamIiYlBenq6UefJzc0ttyOJHjx4AAsLC6XDKBXm5uZwdnZWOgxAmICMjAwBQGRkZCgdChFRqbh37544ffq0uHfvntHHPnwoRJ06QshUJP9DpRLC3V2WK0m3bt0SAERsbGyhZTw8PAQA3cPDw0MIIURYWJho1aqVWLJkifD09BQqlUoIIcRff/0lOnXqJOzs7ETNmjVFr169xPnz53Xne/xcAERAQIAQQohDhw6JwMBAUatWLWFrayv8/f1FXFxcoXGFhYXlO9eOHTtEUlKSACBWrlwp/P39hVqtFpGRkUIIIZYsWSKaNGki1Gq1aNy4sYiIiNCdL++4devWiS5dughra2vRsmVLsW/fPr3nXbt2rWjWrJmwtLQUHh4eYtasWbq/zZ8/XzRv3ly3vX79egFALFy4ULevW7du4pNPPhFCCHH+/HnRu3dv4ejoKKpVqybatWsntm7dmu/1/+KLL0RoaKiwsbER7u7uYtGiRfniPnbsmBBCiIcPH4oRI0YIT09PYWVlJRo1aiTmzJlT6OsoRNHvXUO/v5mMEBGVA8+SjOzYUXgi8vhjx46SjfnBgwfCxsZGjB8/Xty/f7/AMmlpaQKAiIyMFMnJySItLU0IIZOBatWqiZ49e4qjR4+K48ePCyHkl/W6devEuXPnxLFjx0RwcLBo0aKF0Gg0QgiZdAAQ27ZtE8nJySI9PV0IIURMTIxYtmyZSEhIEKdPnxZvvPGGcHJyEpmZmQXGlZWVJV555RXRs2dPkZycLJKTk0VOTo7uy9nT01OsW7dOXLx4UVy7dk0sX75cuLi46PatW7dO1KxZU0RFRQkhHn2pN2nSRPzxxx8iMTFRDBw4UHh4eIgHDx4IIYQ4cuSIMDMzE5999plITEwUkZGRwtraWpfsnDhxQqhUKt1rNH78eFG7dm0xaNAgIYQQubm5omrVqrqEIz4+Xvzwww/i5MmT4uzZs+LTTz8VVlZW4vLly7rr9PDwEDVr1hQRERHi3LlzIjw8XJiZmYkzZ87oxZ2XjOTm5oqpU6eKw4cPi4sXL4rly5eLqlWrilWrVhX6PmAyQkRUQTxLMrJihWHJyIoVJR/32rVrhb29vbCyshK+vr5i8uTJusQiDwCxfv16vX1hYWHCwsJC98VbmOvXrwsA4uTJk0KI/F+ehdFoNKJ69eri999/L7RMSEiI6NOnj96+vPM/WRtQv359seKJF3DGjBnCx8dH77gff/xR9/dTp04JACIhIUEIIcSQIUNE9+7d9c7xwQcfiGbNmgkhhNBqtaJWrVpizZo1QgghvL29RXh4uHB2dhZCCLFnzx5hYWEhsrOzC72m5s2bi/nz5+u2PTw8xOuvv67b1mq1wtHRUVfbYsjrOW7cODFgwIBC/14SyQg7sBIRmThDlwR5hqVDCjVgwABcu3YNv/32G3r27InY2Fi0adMGUVFRTz3Ww8MDDg4OevvOnTuHwYMHo169erC1tYWnpycA4MqVK0WeKzU1FaNGjULDhg1hZ2cHW1tb3Llz56nHFaZdu3a6/8/OzsaFCxfwxhtvwMbGRvf4/PPPceHCBb3jWrZsqfv/vLVa8tZuSUhIQKdOnfTKd+rUCefOnYNGo4FKpYK/vz9iY2Nx+/ZtnD59GmPHjkVOTg7OnDmDnTt3on379roZT+/cuYOJEyeiadOmqFGjBmxsbJCQkJDvmh+PSaVSwdnZWRdTQSIiItC2bVs4ODjAxsYGixcvLvbraCh2YCUiMnF+fkCdOrKz6pMdWAFApZJ/9/Mrnee3srJC9+7d0b17d0yZMgUjR45EWFgYhg8fXuRx1apVy7cvODgYHh4eWLJkCVxdXaHVauHl5YXc3NwizxUSEoL09HTMnTsXHh4eUKvV8PHxeepxhsR2584dAMCSJUvQsWNHvXJPrsXyeEfXvJlJjVmFuUuXLli8eDF2796N1q1bw9bWVpeg7Ny5EwEBAbqyEydOxNatWzFr1iw0aNAA1tbWGDhwYL5rfrLzrUqlKjSmlStXYuLEifj222/h4+OD6tWrY+bMmTh48KDB11AcTEaIiEycuTkwd64cNaNS6SckeTN1z5kjy5WFZs2a6Q3ltbCw0K29U5T09HQkJiZiyZIl8Pv/mdOePXv0yuSNuHnyfHv37sX333+PF198EQBw9epV3Lhxo8jns7S0NCguJycnuLq64uLFi3jttdeeWr4wTZs21RvynBd3o0aNdElNQEAAxo8fjzVr1qBLly4AZIKybds27N27F//5z3/0jh0+fDj69esHQCZNly5dKnZ8eef09fXF2LFjdfuerP0pDWymISKqAPr3l8N33dz099epU3rDetPT0/HCCy9g+fLlOHHiBJKSkrBmzRp888036NOnj66cp6cnYmJikJKSglu3bhV6Pnt7e9SqVQuLFy/G+fPnsX37dkyYMEGvjKOjI6ytrbFp0yakpqYiIyMDANCwYUMsW7YMCQkJOHjwIF577TXdirKF8fT0xIkTJ5CYmIgbN24UudDb9OnTER4ejnnz5uHs2bM4efIkIiMjMXv2bENeKgDAf/7zH8TExGDGjBk4e/Ysfv75ZyxYsAATJ07UlWnZsiXs7e2xYsUKvWRkw4YNyMnJ0WvmadiwIaKjoxEfH4/jx49jyJAhRtXCFKRhw4Y4cuQINm/ejLNnz2LKlCk4fPjwM53TEExGiIgqiP79gUuXgB07gBUr5H+TkkonEQEAGxsbdOzYEd999x38/f3h5eWFKVOmYNSoUViwYIGu3LfffoutW7fC3d0drVu3LvR8ZmZmWLlyJeLi4uDl5YX3338fM2fO1CtTpUoVzJs3D4sWLYKrq6su6Vm6dClu3bqFNm3aYOjQoXj33Xfh6OhYZPyjRo1C48aN0a5dOzg4OOSrtXjcyJEj8eOPPyIyMhItWrRAQEAAoqKiULduXUNeKgBAmzZtsHr1aqxcuRJeXl6YOnUqPvvsM73mLJVKBT8/P6hUKnTu3BmATFBsbW3Rrl07veaj2bNnw97eHr6+vggODkZQUBDatGljcDwFGTNmDPr3749BgwahY8eOSE9P16slKS0qIQpqYSxfMjMzYWdnh4yMDNja2iodDhFRibt//z6SkpJQt25dWFlZKR0OkcGKeu8a+v3NmhEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlIUkxEiIqISMHz4cPTt21e33aVLF4wfP77IYzw9PTFnzhxFYygPmIwQEVGxXb9+HW+99Raee+45qNVqODs7IygoSG+dF5VKpbeK77O4dOkSVCoV4uPjS+R8pSk6OhozZswo0+ecO3cuoqKiFI2hOKooHQAREZmuAQMGIDc3Fz///DPq1auH1NRUxMTEID093ajz5ObmwtLSspSiVEbNmjXL/Dnt7OwUj6E4ilUzEhERAU9PT1hZWaFjx444dOhQkeVv376NcePGwcXFBWq1Go0aNcLGjRuLFTARUWUgBJCdrczD0OVTb9++jd27d+Prr79G165d4eHhgQ4dOmDy5Mno3bs3ANkMAQD9+vWDSqXSbU+bNg3e3t748ccf9RZY27RpEzp37owaNWqgVq1aeOmll3DhwgXdc+atktu6dWuoVCp06dIFAHD48GF0794dtWvXhp2dHQICAnD06NFCY//7779hZmaG69evAwBu3rwJMzMzvPrqq7oyn3/+uW7lXI1GgzfeeAN169aFtbU1GjdujLlz5xb5+jzZRJKWlobg4GBYW1ujbt26+OWXX/IdM3v2bLRo0QLVqlWDu7s7xo4dizt37uiV2bt3L7p06YKqVavC3t4eQUFBuHXrFoBK1EyzatUqTJgwAWFhYTh69ChatWqFoKAgpKWlFVg+NzcX3bt3x6VLl7B27VokJiZiyZIlcHNze+bgiYgqqrt3ARsbZR537xoWo42NDWxsbLBhwwbk5OQUWObw4cMAgMjISCQnJ+u2AeD8+fNYt24doqOjdc0u2dnZmDBhAo4cOYKYmBiYmZmhX79+0Gq1AKD78btt2zYkJycjOjoaAJCVlYWQkBDs2bMHBw4cQMOGDfHiiy8iKyurwLiaN2+OWrVqYefOnQCA3bt3620DwM6dO3XJjlarRZ06dbBmzRqcPn0aU6dOxccff4zVq1cb9mJBJgpXr17Fjh07sHbtWnz//ff5vjvNzMwwb948nDp1Cj///DO2b9+ODz/8UPf3+Ph4dOvWDc2aNcP+/fuxZ88eBAcHQ6PRGBxHuSSM1KFDBzFu3DjdtkajEa6uriI8PLzA8gsXLhT16tUTubm5xj6VTkZGhgAgMjIyin0OIqLy7N69e+L06dPi3r17Qggh7twRQtZRlP3jzh3D4167dq2wt7cXVlZWwtfXV0yePFkcP35crwwAsX79er19YWFhwsLCQqSlpRV5/uvXrwsA4uTJk0IIIZKSkgQAcezYsSKP02g0onr16uL3338vtEz//v1132fjx48XH3zwgbC3txcJCQkiNzdXVK1aVWzZsqXQ48eNGycGDBig2w4JCRF9+vTRbQcEBIj33ntPCCFEYmKiACAOHTqk+3tCQoIAIL777rtCn2PNmjWiVq1auu3BgweLTp06FVq+qBhKy5Pv3ccZ+v1tVM1Ibm4u4uLiEBgYqNtnZmaGwMBA7N+/v8BjfvvtN/j4+GDcuHFwcnKCl5cXvvzyyyKzuJycHGRmZuo9iIgqk6pVgTt3lHlUrWp4nAMGDMC1a9fw22+/oWfPnoiNjUWbNm30OlEWxsPDAw4ODnr7zp07h8GDB6NevXqwtbXVNetcuXKlyHOlpqZi1KhRaNiwIezs7GBra4s7d+4UeVxAQABiY2MByFqQF154Af7+/oiNjcXhw4fx4MEDdOrUSVc+IiICbdu2hYODA2xsbLB48eKnxpUnISEBVapUQdu2bXX7mjRpgho1auiV27ZtG7p16wY3NzdUr14dQ4cORXp6Ou7+/+qqvJqRisaoZOTGjRvQaDRwcnLS2+/k5ISUlJQCj7l48SLWrl0LjUaDjRs3YsqUKfj222/x+eefF/o84eHhsLOz0z3c3d2NCZOIyOSpVEC1aso8VCrjYrWyskL37t0xZcoU7Nu3D8OHD0dYWNhTj6tWrVq+fcHBwbh58yaWLFmCgwcP4uDBgwDkj+GihISEID4+HnPnzsW+ffsQHx+PWrVqFXlcly5dcPr0aZw7dw6nT59G586d0aVLF8TGxmLnzp1o164dqv7/zGzlypWYOHEi3njjDWzZsgXx8fEIDQ19alzGuHTpEl566SW0bNkS69atQ1xcHCIiIvSu39rausSerzwp9aG9Wq0Wjo6OWLx4Mdq2bYtBgwbhk08+wQ8//FDoMZMnT0ZGRobucfXq1dIOk4iISkizZs2QnZ2t27awsDCoT0N6ejoSExPx6aefolu3bmjatKmuY2aevBE3T55v7969ePfdd/Hiiy+iefPmUKvVuHHjRpHP16JFC9jb2+Pzzz+Ht7c3bGxs0KVLF+zcuROxsbG6/iJ55/f19cXYsWPRunVrNGjQQK9j7dM0adIEDx8+RFxcnG5fYmIibt++rduOi4uDVqvFt99+i+effx6NGjXCtWvX9M7TsmVLxMTEGPy8psKoZKR27dowNzdHamqq3v7U1FQ4OzsXeIyLiwsaNWoEc3Nz3b6mTZsiJSWl0IxSrVbD1tZW70FEROVLeno6XnjhBSxfvhwnTpxAUlIS1qxZg2+++QZ9+vTRlfP09ERMTAxSUlLyJRePs7e3R61atbB48WKcP38e27dvx4QJE/TKODo6wtraGps2bUJqaioyMjIAAA0bNsSyZcuQkJCAgwcP4rXXXntqLYJKpYK/vz9++eUXXeLRsmVL5OTkICYmBgEBAbqyDRs2xJEjR7B582acPXsWU6ZM0euM+zSNGzdGz549MWbMGBw8eBBxcXEYOXKkXowNGjTAgwcPMH/+fFy8eBHLli3L98N98uTJOHz4MMaOHYsTJ07gzJkzWLhw4VMTr/LOqGTE0tISbdu21cvKtFotYmJi4OPjU+AxnTp1wvnz53U9oQHg7NmzcHFxqXBjyomIKhMbGxt07NgR3333Hfz9/eHl5YUpU6Zg1KhRWLBgga7ct99+i61bt8Ld3R2tW7cu9HxmZmZYuXIl4uLi4OXlhffffx8zZ87UK1OlShXMmzcPixYtgqurqy7pWbp0KW7duoU2bdpg6NChePfdd+Ho6PjUawgICIBGo9ElI2ZmZvD394dKpdLrLzJmzBj0798fgwYNQseOHZGeno6xY8ca83IhMjISrq6uCAgIQP/+/TF69Gi9GFu1aoXZs2fj66+/hpeXF3755ReEh4frnaNRo0bYsmULjh8/jg4dOsDHxwf/+9//UKWKaU8bphLC0BHl0qpVqxASEoJFixahQ4cOmDNnDlavXo0zZ87AyckJw4YNg5ubm+4FvHr1Kpo3b46QkBC88847OHfuHEaMGIF3330Xn3zyiUHPmZmZCTs7O2RkZLCWhIgqpPv37yMpKUlvzg0iYw0ePBjm5uZYvnx5mT1nUe9dQ7+/jU6lBg0ahOvXr2Pq1KlISUmBt7c3Nm3apOvUeuXKFZiZPapwcXd3x+bNm/H++++jZcuWcHNzw3vvvYePPvrI2KcmIiKiAjx8+BBnz57F/v37MWbMGKXDMZrRNSNKYM0IEVV0rBmhZxEfHw9fX1907doVy5cvh729fZk9tyI1I0RERFS+eHt76+YiMUVctZeIiIgUxWSEiKgcMYGWcyI9JfGeZTJCRFQO5M3FVJIzehKVhbzmIQsLi2Kfg31GiIjKgSpVqqBq1aq4fv06LCws9EYlEpVHQgjcvXsXaWlpqFGjht7kpsZiMkJEVA6oVCq4uLggKSkJly9fVjocIoPVqFGj0FnYDcVkhIionLC0tETDhg3ZVEMmw8LC4plqRPIwGSEiKkfMzMw4zwhVOmyUJCIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUxGSEiIiJFMRkhIiIiRTEZISIiIkUVKxmJiIiAp6cnrKys0LFjRxw6dMig41auXAmVSoW+ffsW52mJiIioAjI6GVm1ahUmTJiAsLAwHD16FK1atUJQUBDS0tKKPO7SpUuYOHEi/Pz8ih0sERERVTxGJyOzZ8/GqFGjEBoaimbNmuGHH35A1apV8dNPPxV6jEajwWuvvYbp06ejXr16zxQwERERVSxGJSO5ubmIi4tDYGDgoxOYmSEwMBD79+8v9LjPPvsMjo6OeOONNwx6npycHGRmZuo9iIiIqGIyKhm5ceMGNBoNnJyc9PY7OTkhJSWlwGP27NmDpUuXYsmSJQY/T3h4OOzs7HQPd3d3Y8IkIiIiE1Kqo2mysrIwdOhQLFmyBLVr1zb4uMmTJyMjI0P3uHr1ailGSUREREqqYkzh2rVrw9zcHKmpqXr7U1NT4ezsnK/8hQsXcOnSJQQHB+v2abVa+cRVqiAxMRH169fPd5xarYZarTYmNCIiIjJRRtWMWFpaom3btoiJidHt02q1iImJgY+PT77yTZo0wcmTJxEfH6979O7dG127dkV8fDybX4iIiMi4mhEAmDBhAkJCQtCuXTt06NABc+bMQXZ2NkJDQwEAw4YNg5ubG8LDw2FlZQUvLy+942vUqAEA+fYTERFR5WR0MjJo0CBcv34dU6dORUpKCry9vbFp0yZdp9YrV67AzIwTuxIREZFhVEIIoXQQT5OZmQk7OztkZGTA1tZW6XCIiIjIAIZ+f7MKg4iIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUxWSEiIiIFMVkhIiIiBTFZISIiIgUVUXpAJSi0QC7dwPJyYCLC+DnB5ibKx0VERFR5VMpk5HoaOC994B//nm0r04dYO5coH9/5eIiIiKqjCpdM010NDBwoH4iAgD//iv3R0crExcREVFlVamSEY1G1ogIkf9vefvGj5fliIiIqGxUqmRk9+78NSKPEwK4elWWIyIiorJRqZKR5OSSLUdERETPrlIlIy4uJVuOiIiInl2lSkb8/OSoGZWq4L+rVIC7uyxHREREZaNSJSPm5nL4LpA/IcnbnjOH840QERGVpUqVjAByHpG1awE3N/39derI/ZxnhIiIqGxVyknP+vcH+vThDKxERETlQaVMRgCZeHTponQUREREVOmaaYiIiKh8YTJCREREimIyQkRERIpiMkJERESKYjJCREREimIyQkRERIpiMkJERESKKlYyEhERAU9PT1hZWaFjx444dOhQoWWXLFkCPz8/2Nvbw97eHoGBgUWWJyIiosrF6GRk1apVmDBhAsLCwnD06FG0atUKQUFBSEtLK7B8bGwsBg8ejB07dmD//v1wd3dHjx498O+//z5z8ERERGT6VEIIYcwBHTt2RPv27bFgwQIAgFarhbu7O9555x1MmjTpqcdrNBrY29tjwYIFGDZsmEHPmZmZCTs7O2RkZMDW1taYcImIiEghhn5/G1Uzkpubi7i4OAQGBj46gZkZAgMDsX//foPOcffuXTx48AA1a9YstExOTg4yMzP1HkRERFQxGZWM3LhxAxqNBk5OTnr7nZyckJKSYtA5PvroI7i6uuolNE8KDw+HnZ2d7uHu7m5MmERERGRCynQ0zVdffYWVK1di/fr1sLKyKrTc5MmTkZGRoXtcvXq1DKMkIiKismTUqr21a9eGubk5UlNT9fanpqbC2dm5yGNnzZqFr776Ctu2bUPLli2LLKtWq6FWq40JjYiIiEyUUTUjlpaWaNu2LWJiYnT7tFotYmJi4OPjU+hx33zzDWbMmIFNmzahXbt2xY+WiIiIKhyjakYAYMKECQgJCUG7du3QoUMHzJkzB9nZ2QgNDQUADBs2DG5ubggPDwcAfP3115g6dSpWrFgBT09PXd8SGxsb2NjYlOClEBERkSkyOhkZNGgQrl+/jqlTpyIlJQXe3t7YtGmTrlPrlStXYGb2qMJl4cKFyM3NxcCBA/XOExYWhmnTpj1b9ERERGTyjJ5nRAmcZ4SIiMj0lMo8I0REREQljckIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESmKyQgREREpiskIERERKYrJCBERESnK6OngicoLjQbYvRtITgZcXAA/P8DcXOmoiIjIWExGyCRFRwPvvQf888+jfXXqAHPnAv37KxcXEREZj800ZHKio4GBA/UTEQD491+5PzpambiIiKh4mIyQSdFoZI1IQcs75u0bP16WIyIi08BkhEzK7t35a0QeJwRw9aosR0REpoHJCJmU5OSSLUdERMpjMkImxcWlZMsREZHymIyQSfHzk6NmVKqC/65SAe7ushwREZkGJiNkUszN5fBdIH9Ckrc9Zw7nGyEiMiVMRsjk9O8PrF0LuLnp769TR+7nPCOmQ6MBYmOBX3+V/+UoKKLKiZOekUnq3x/o04czsJoyTlxHRHlUQhQ0Y0P5kpmZCTs7O2RkZMDW1lbpcIjoGeVNXPfkvz55TW2s4SKqGAz9/mYzDRGVKU5cR0RPYjJCRGWKE9cR0ZPYZ4SIyhQnrqs4uHI2lRQmI0RUpjhxXcXADshUkthMQ0RlihPXmT6unE0ljckIEZUpTlxn2tgBuWIpL3P9MBkhojLHietMFzsgVxzR0YCnJ9C1KzBkiPyvp6cyNVvsM0JEiuDEdaaJHZArhsLm+slraivrHwVMRohIMebmQJcuSkdBxmAHZNP3tKY2lUo2tfXpU3Y/DthMQ0REBmMHZNNXHpvamIwQEZHB2AHZ9JXHpjYmI0REZBR2QDZt5bGpjQvlERFRsXAGVtOk0chRM//+W3C/EZVKJpZJSc9+Pw39/mYHViIiKhZ2QDZNeU1tAwfKxOPxhESppjY20xAREVUy5a2pjTUjRERElVB5muuHyQgREVElVV6a2thMQ0RERIpiMkJERESKYjJCREREimIyQkRERIpiMkJERESKYjJCREREimIyQkRERIpiMkJERESKYjJCREREijKJGVjzFhbOzMxUOBIiIiIyVN73tihoeeDHmEQykpWVBQBwd3dXOBIiIiIyVlZWFuzs7Ar9u0o8LV0pB7RaLa5du4bq1atDlbe+cQnIzMyEu7s7rl69Cltb2xI7b3lS0a+R12f6Kvo18vpMX0W/xtK8PiEEsrKy4OrqCjOzwnuGmETNiJmZGerUqVNq57e1ta2Qb7DHVfRr5PWZvop+jbw+01fRr7G0rq+oGpE87MBKREREimIyQkRERIqq1MmIWq1GWFgY1Gq10qGUmop+jbw+01fRr5HXZ/oq+jWWh+sziQ6sREREVHFV6poRIiIiUh6TESIiIlIUkxEiIiJSFJMRIiIiUhSTESIiIlJUhU9GIiIi4OnpCSsrK3Ts2BGHDh0qsvyaNWvQpEkTWFlZoUWLFti4cWMZRVp8xlxjVFQUVCqV3sPKyqoMozXOrl27EBwcDFdXV6hUKmzYsOGpx8TGxqJNmzZQq9Vo0KABoqKiSj3O4jL2+mJjY/PdP5VKhZSUlLIJ2Ejh4eFo3749qlevDkdHR/Tt2xeJiYlPPc5UPofFuT5T+wwuXLgQLVu21M3O6ePjg7/++qvIY0zl/gHGX5+p3b8nffXVV1CpVBg/fnyR5cr6HlboZGTVqlWYMGECwsLCcPToUbRq1QpBQUFIS0srsPy+ffswePBgvPHGGzh27Bj69u2Lvn374u+//y7jyA1n7DUCcsrf5ORk3ePy5ctlGLFxsrOz0apVK0RERBhUPikpCb169ULXrl0RHx+P8ePHY+TIkdi8eXMpR1o8xl5fnsTERL176OjoWEoRPpudO3di3LhxOHDgALZu3YoHDx6gR48eyM7OLvQYU/ocFuf6ANP6DNapUwdfffUV4uLicOTIEbzwwgvo06cPTp06VWB5U7p/gPHXB5jW/Xvc4cOHsWjRIrRs2bLIcorcQ1GBdejQQYwbN063rdFohKurqwgPDy+w/CuvvCJ69eqlt69jx45izJgxpRrnszD2GiMjI4WdnV0ZRVeyAIj169cXWebDDz8UzZs319s3aNAgERQUVIqRlQxDrm/Hjh0CgLh161aZxFTS0tLSBACxc+fOQsuY4ucwjyHXZ8qfwTz29vbixx9/LPBvpnz/8hR1faZ6/7KyskTDhg3F1q1bRUBAgHjvvfcKLavEPaywNSO5ubmIi4tDYGCgbp+ZmRkCAwOxf//+Ao/Zv3+/XnkACAoKKrS80opzjQBw584deHh4wN3d/am/AEyNqd3D4vL29oaLiwu6d++OvXv3Kh2OwTIyMgAANWvWLLSMKd9DQ64PMN3PoEajwcqVK5GdnQ0fH58Cy5jy/TPk+gDTvH/jxo1Dr1698t2bgihxDytsMnLjxg1oNBo4OTnp7Xdyciq0fT0lJcWo8korzjU2btwYP/30E/73v/9h+fLl0Gq18PX1xT///FMWIZe6wu5hZmYm7t27p1BUJcfFxQU//PAD1q1bh3Xr1sHd3R1dunTB0aNHlQ7tqbRaLcaPH49OnTrBy8ur0HKm9jnMY+j1meJn8OTJk7CxsYFarcabb76J9evXo1mzZgWWNcX7Z8z1meL9W7lyJY4ePYrw8HCDyitxD6uU2pmpXPLx8dHL+H19fdG0aVMsWrQIM2bMUDAyMkTjxo3RuHFj3bavry8uXLiA7777DsuWLVMwsqcbN24c/v77b+zZs0fpUEqFoddnip/Bxo0bIz4+HhkZGVi7di1CQkKwc+fOQr+wTY0x12dq9+/q1at47733sHXr1nLd0bbCJiO1a9eGubk5UlNT9fanpqbC2dm5wGOcnZ2NKq+04lzjkywsLNC6dWucP3++NEIsc4XdQ1tbW1hbWysUVenq0KFDuf+Cf/vtt/HHH39g165dqFOnTpFlTe1zCBh3fU8yhc+gpaUlGjRoAABo27YtDh8+jLlz52LRokX5ypri/TPm+p5U3u9fXFwc0tLS0KZNG90+jUaDXbt2YcGCBcjJyYG5ubneMUrcwwrbTGNpaYm2bdsiJiZGt0+r1SImJqbQtkAfHx+98gCwdevWItsOlVSca3ySRqPByZMn4eLiUlphlilTu4clIT4+vtzePyEE3n77baxfvx7bt29H3bp1n3qMKd3D4lzfk0zxM6jVapGTk1Pg30zp/hWmqOt7Unm/f926dcPJkycRHx+ve7Rr1w6vvfYa4uPj8yUigEL3sNS6xpYDK1euFGq1WkRFRYnTp0+L0aNHixo1aoiUlBQhhBBDhw4VkyZN0pXfu3evqFKlipg1a5ZISEgQYWFhwsLCQpw8eVKpS3gqY69x+vTpYvPmzeLChQsiLi5OvPrqq8LKykqcOnVKqUsoUlZWljh27Jg4duyYACBmz54tjh07Ji5fviyEEGLSpEli6NChuvIXL14UVatWFR988IFISEgQERERwtzcXGzatEmpSyiSsdf33XffiQ0bNohz586JkydPivfee0+YmZmJbdu2KXUJRXrrrbeEnZ2diI2NFcnJybrH3bt3dWVM+XNYnOsztc/gpEmTxM6dO0VSUpI4ceKEmDRpklCpVGLLli1CCNO+f0IYf32mdv8K8uRomvJwDyt0MiKEEPPnzxfPPfecsLS0FB06dBAHDhzQ/S0gIECEhITolV+9erVo1KiRsLS0FM2bNxd//vlnGUdsPGOucfz48bqyTk5O4sUXXxRHjx5VIGrD5A1lffKRd00hISEiICAg3zHe3t7C0tJS1KtXT0RGRpZ53IYy9vq+/vprUb9+fWFlZSVq1qwpunTpIrZv365M8AYo6NoA6N0TU/4cFuf6TO0zOGLECOHh4SEsLS2Fg4OD6Natm+6LWgjTvn9CGH99pnb/CvJkMlIe7qFKCCFKr96FiIiIqGgVts8IERERmQYmI0RERKQoJiNERESkKCYjREREpCgmI0RERKQoJiNERESkKCYjREREpCgmI0RERKQoJiNERESkKCYjREREpCgmI0RERKSo/wcWdHJfuBJGLgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Strata trenowania')\n",
    "plt.plot(epochs, val_loss, 'b', label='Strata walidacji')\n",
    "plt.title('Strata trenowania i walidacji')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T10:13:28.874477500Z",
     "start_time": "2024-01-18T10:13:28.746619300Z"
    }
   },
   "id": "8aca5ee024643350",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std[3] 1928.5890690107578\n"
     ]
    }
   ],
   "source": [
    "np_array = df.to_numpy()\n",
    "#print(np_array)\n",
    "\n",
    "train_max_range = 6000\n",
    "val_max_range = train_max_range + 2000\n",
    "\n",
    "close_price = np_array[:, 3]\n",
    "#print(close_price)\n",
    "\n",
    "mean = np_array[:train_max_range].mean(axis=0)\n",
    "np_array -= mean\n",
    "std = np_array[:train_max_range].std(axis=0)\n",
    "np_array /= std\n",
    "print('std[3]', std[3])\n",
    "\n",
    "#print(np_array)\n",
    "\n",
    "lookback = 1\n",
    "step = 1\n",
    "delay = 10\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(np_array, lookback=lookback, delay=delay, min_index=0, max_index=train_max_range, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "val_gen = generator(np_array, lookback=lookback, delay=delay, min_index=train_max_range+1, max_index=val_max_range,\n",
    "                    shuffle=True, step=step, batch_size=batch_size)\n",
    "test_gen = generator(np_array, lookback=lookback, delay=delay, min_index=val_max_range+1, max_index=None, shuffle=False, step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (val_max_range - train_max_range - 1 - lookback) // batch_size\n",
    "test_steps = (len(np_array) - val_max_range - 1 - lookback) // batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:56:44.815586700Z",
     "start_time": "2024-01-18T13:56:44.785537800Z"
    }
   },
   "id": "1f4f3355affccdde",
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_116 (GRU)               (None, None, 4)           3396      \n",
      "                                                                 \n",
      " gru_117 (GRU)               (None, 8)                 336       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,741\n",
      "Trainable params: 3,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmarcinski\\AppData\\Local\\Temp\\ipykernel_9528\\3901989567.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=200, epochs=20,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 30ms/step - loss: 0.4128 - val_loss: 1.0769\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.2180 - val_loss: 1.0050\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1941 - val_loss: 1.0595\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.1751 - val_loss: 1.1258\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.1582 - val_loss: 1.0518\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1442 - val_loss: 1.0677\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1330 - val_loss: 1.1485\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.1235 - val_loss: 1.1654\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1171 - val_loss: 1.0828\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1120 - val_loss: 1.1289\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.1087 - val_loss: 1.1784\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1064 - val_loss: 1.1344\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1048 - val_loss: 1.1053\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1025 - val_loss: 1.1269\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.1016 - val_loss: 1.1371\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.1007 - val_loss: 1.1508\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.0989 - val_loss: 1.1168\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.0987 - val_loss: 1.1368\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.0980 - val_loss: 1.1473\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.0955 - val_loss: 1.1390\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(4,\n",
    "              dropout=0.3, recurrent_dropout=0.5, return_sequences=True, input_shape=(None, np_array.shape[-1])))\n",
    "model.add(GRU(8, activation='relu', dropout=0.2, recurrent_dropout=0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "print(model.summary())\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=200, epochs=20,\n",
    "                              validation_data=val_gen, validation_steps=val_steps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:30:46.442920600Z",
     "start_time": "2024-01-18T13:28:29.474069300Z"
    }
   },
   "id": "ef4774d6b4629105",
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets [3.54465665 3.52563757 3.49517488 3.50830365 3.53835671 3.52836495\n",
      " 3.53613229 3.55893652 3.55781135 3.53394416 3.56013429 3.58483628\n",
      " 3.65658304 3.67880654 3.64186243 3.64028096 3.60855311 3.58940958\n",
      " 3.58168891 3.56516387 3.52235537 3.54473961 3.51877763 3.5451648\n",
      " 3.56252982 3.62075373 3.62858848 3.61138938 3.58194816 3.54243223\n",
      " 3.58041336 3.59167548 3.59265029 3.57503637 3.58951328 3.61526786\n",
      " 3.63422472 3.60282871 3.59509249 3.57012086 3.56794829 3.65794673\n",
      " 3.69949524 3.73115569 3.7318142  3.76451686 3.80280392 3.78984108\n",
      " 3.87020553 3.85850267 3.89222162 3.95549067 3.97186015 3.97631419\n",
      " 3.97081275 3.94637002 3.93054497 3.96395282 3.93945304 3.91726065\n",
      " 3.9409671  3.93382717 3.93284199 3.90954517 3.89723046 3.87909285\n",
      " 3.89734972 3.92801463 3.9145229  3.90479558 3.927465   3.90953998\n",
      " 3.84947016 3.87404771 3.87773953 3.91996211 3.94732408 3.99419773\n",
      " 3.9501448  4.05176313 4.03083591 4.06724595 4.0692163  4.10828113\n",
      " 4.11224776 4.17836345 4.14194304 4.08196137 4.11028259 4.08744724\n",
      " 4.09267386 4.05961861 4.07486291 4.02923889 4.0466765  4.14271044\n",
      " 4.1950233  4.11832474 4.00520059 4.01917453 4.03169664 4.06039638\n",
      " 4.05210016 4.1203262  4.07095851 4.01351755 4.03457439 4.0555742\n",
      " 4.02611743 4.06331561 4.08763909 4.08759761 4.07442736 4.04962166\n",
      " 4.09419829 4.12580171 4.1593651  4.15597921 4.13650902 4.11740697\n",
      " 4.1039308  4.11703882 4.13305571 4.14693633 4.19863215 4.24468655\n",
      " 4.27637292 4.31851772]\n",
      "targets [4.3797179  4.33827828 4.28664987 4.30576228 4.35423295 4.37508239\n",
      " 4.32904355 4.30223639 4.33110205 4.33095687 4.27700551 4.31467035\n",
      " 4.31094742 4.28958984 4.28001807 4.30919484 4.33261611 4.3369457\n",
      " 4.33402128 4.36788542 4.30970817 4.08983241 4.04009138 4.05726974\n",
      " 4.04370542 3.97909342 3.99607993 3.96992091 3.85363901 3.91013109\n",
      " 3.93420568 3.99319699 4.0123146  3.99317107 3.99509994 3.96800241\n",
      " 3.96699131 3.99379328 4.02083378 4.0340144  4.06075415 4.04889056\n",
      " 4.02307894 3.99572216 4.09069314 4.12284618 4.08387987 4.0683452\n",
      " 4.0653793  4.06818446 4.03886769 4.03096035 4.05305422 3.99244515\n",
      " 4.03094998 4.0309448  4.06137119 4.06191562 3.94136117 3.93185163\n",
      " 3.94371004 3.97431272 3.97657344 4.025153   3.94830407 3.9262465\n",
      " 3.9454678  3.956284   3.95779806 3.94757815 3.95835805 3.98271783\n",
      " 4.00535096 4.05694826 4.03297737 4.03547661 4.03629586 4.01483976\n",
      " 4.08597466 4.10547597 4.07997027 4.08543541 4.07217701 4.08625985\n",
      " 4.09885973 4.17690642 4.15783549 4.04111804 4.09317164 4.04724168\n",
      " 4.08490653 4.10626929 4.09899973 4.09662494 4.13929862 4.13465274\n",
      " 4.15578736 4.19147666 4.17811456 4.2036047  4.1559118  4.21127352\n",
      " 4.22051343 4.21417201 4.19429219 4.18499005 4.15664809 4.16057843\n",
      " 4.18489154 4.20891428 4.17498792 4.18845373 4.18449747 4.07196442\n",
      " 4.08340284 4.11746401 4.11613143 4.15832289 4.18618264 4.17769457\n",
      " 4.19165296 4.17948344 4.17034723 4.1884641  4.24293397 4.20616097\n",
      " 4.13465792 4.16471098]\n",
      "[[1.6692052]\n",
      " [1.6752946]\n",
      " [1.6913775]\n",
      " [1.7005084]\n",
      " [1.6914895]\n",
      " [1.6826134]\n",
      " [1.700766 ]\n",
      " [1.6903882]\n",
      " [1.6854582]\n",
      " [1.6839193]\n",
      " [1.7000024]\n",
      " [1.6772718]\n",
      " [1.6733272]\n",
      " [1.6603874]\n",
      " [1.6787703]\n",
      " [1.6940303]\n",
      " [1.6888018]\n",
      " [1.6945211]\n",
      " [1.702717 ]\n",
      " [1.7082698]\n",
      " [1.6981524]\n",
      " [1.7032348]\n",
      " [1.7091033]\n",
      " [1.6398937]\n",
      " [1.6261848]\n",
      " [1.6141787]\n",
      " [1.6127867]\n",
      " [1.5788826]\n",
      " [1.5270633]\n",
      " [1.548635 ]\n",
      " [1.5396749]\n",
      " [1.5378127]\n",
      " [1.5703033]\n",
      " [1.539559 ]\n",
      " [1.5844448]\n",
      " [1.6114283]\n",
      " [1.6079712]\n",
      " [1.6630607]\n",
      " [1.6642578]\n",
      " [1.669296 ]\n",
      " [1.644215 ]\n",
      " [1.6536534]\n",
      " [1.6666389]\n",
      " [1.6623485]\n",
      " [1.6695747]\n",
      " [1.698869 ]\n",
      " [1.7037418]\n",
      " [1.6999557]\n",
      " [1.6876384]\n",
      " [1.6909735]\n",
      " [1.6909508]\n",
      " [1.6834791]\n",
      " [1.6736168]\n",
      " [1.6368972]\n",
      " [1.5637861]\n",
      " [1.5457907]\n",
      " [1.4980905]\n",
      " [1.4823831]\n",
      " [1.5309063]\n",
      " [1.4208332]\n",
      " [1.4411429]\n",
      " [1.4627583]\n",
      " [1.511509 ]\n",
      " [1.5285449]\n",
      " [1.4808636]\n",
      " [1.5001034]\n",
      " [1.4717371]\n",
      " [1.4683034]\n",
      " [1.5116429]\n",
      " [1.5062174]\n",
      " [1.4604838]\n",
      " [1.4698656]\n",
      " [1.498042 ]\n",
      " [1.4963535]\n",
      " [1.4815491]\n",
      " [1.484265 ]\n",
      " [1.5186479]\n",
      " [1.5493641]\n",
      " [1.5694568]\n",
      " [1.5748688]\n",
      " [1.5798457]\n",
      " [1.6154385]\n",
      " [1.6177936]\n",
      " [1.556817 ]\n",
      " [1.5351613]\n",
      " [1.5621631]\n",
      " [1.5930126]\n",
      " [1.5686237]\n",
      " [1.6384007]\n",
      " [1.6185197]\n",
      " [1.6433773]\n",
      " [1.6386827]\n",
      " [1.66649  ]\n",
      " [1.6458658]\n",
      " [1.6058279]\n",
      " [1.5979857]\n",
      " [1.6147982]\n",
      " [1.6055747]\n",
      " [1.5880573]\n",
      " [1.5886357]\n",
      " [1.5556307]\n",
      " [1.5552765]\n",
      " [1.5375015]\n",
      " [1.5784478]\n",
      " [1.5689648]\n",
      " [1.5820463]\n",
      " [1.6294763]\n",
      " [1.6005267]\n",
      " [1.5955993]\n",
      " [1.5696578]\n",
      " [1.5681233]\n",
      " [1.5739071]\n",
      " [1.6066527]\n",
      " [1.599272 ]\n",
      " [1.6260821]\n",
      " [1.6165643]\n",
      " [1.5566157]\n",
      " [1.5585104]\n",
      " [1.587204 ]\n",
      " [1.5509481]\n",
      " [1.6321456]\n",
      " [1.6315019]\n",
      " [1.641691 ]\n",
      " [1.5781696]\n",
      " [1.538552 ]\n",
      " [1.5529174]\n",
      " [1.5611638]\n",
      " [1.6019434]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmarcinski\\AppData\\Local\\Temp\\ipykernel_9528\\1723827779.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(test_gen, steps=1)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_gen, steps=1)\n",
    "print(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:37:35.259322400Z",
     "start_time": "2024-01-18T13:37:35.197275600Z"
    }
   },
   "id": "fd0b017793b38039",
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23295.164]\n",
      " [23306.908]\n",
      " [23337.926]\n",
      " [23355.535]\n",
      " [23338.14 ]\n",
      " [23321.023]\n",
      " [23356.031]\n",
      " [23336.018]\n",
      " [23326.51 ]\n",
      " [23323.541]\n",
      " [23354.559]\n",
      " [23310.72 ]\n",
      " [23303.113]\n",
      " [23278.158]\n",
      " [23313.611]\n",
      " [23343.041]\n",
      " [23332.957]\n",
      " [23343.988]\n",
      " [23359.795]\n",
      " [23370.504]\n",
      " [23350.992]\n",
      " [23360.793]\n",
      " [23372.111]\n",
      " [23238.635]\n",
      " [23212.195]\n",
      " [23189.041]\n",
      " [23186.355]\n",
      " [23120.969]\n",
      " [23021.031]\n",
      " [23062.633]\n",
      " [23045.354]\n",
      " [23041.762]\n",
      " [23104.424]\n",
      " [23045.129]\n",
      " [23131.695]\n",
      " [23183.736]\n",
      " [23177.068]\n",
      " [23283.314]\n",
      " [23285.623]\n",
      " [23295.34 ]\n",
      " [23246.969]\n",
      " [23265.172]\n",
      " [23290.215]\n",
      " [23281.941]\n",
      " [23295.877]\n",
      " [23352.373]\n",
      " [23361.771]\n",
      " [23354.469]\n",
      " [23330.715]\n",
      " [23337.146]\n",
      " [23337.102]\n",
      " [23322.693]\n",
      " [23303.672]\n",
      " [23232.855]\n",
      " [23091.854]\n",
      " [23057.148]\n",
      " [22965.154]\n",
      " [22934.861]\n",
      " [23028.441]\n",
      " [22816.156]\n",
      " [22855.326]\n",
      " [22897.014]\n",
      " [22991.033]\n",
      " [23023.889]\n",
      " [22931.93 ]\n",
      " [22969.035]\n",
      " [22914.33 ]\n",
      " [22907.707]\n",
      " [22991.291]\n",
      " [22980.828]\n",
      " [22892.627]\n",
      " [22910.719]\n",
      " [22965.06 ]\n",
      " [22961.805]\n",
      " [22933.252]\n",
      " [22938.49 ]\n",
      " [23004.8  ]\n",
      " [23064.04 ]\n",
      " [23102.791]\n",
      " [23113.229]\n",
      " [23122.826]\n",
      " [23191.47 ]\n",
      " [23196.012]\n",
      " [23078.414]\n",
      " [23036.648]\n",
      " [23088.725]\n",
      " [23148.219]\n",
      " [23101.184]\n",
      " [23235.754]\n",
      " [23197.412]\n",
      " [23245.354]\n",
      " [23236.299]\n",
      " [23289.928]\n",
      " [23250.152]\n",
      " [23172.936]\n",
      " [23157.81 ]\n",
      " [23190.234]\n",
      " [23172.447]\n",
      " [23138.664]\n",
      " [23139.78 ]\n",
      " [23076.125]\n",
      " [23075.441]\n",
      " [23041.162]\n",
      " [23120.13 ]\n",
      " [23101.842]\n",
      " [23127.07 ]\n",
      " [23218.543]\n",
      " [23162.71 ]\n",
      " [23153.209]\n",
      " [23103.178]\n",
      " [23100.219]\n",
      " [23111.373]\n",
      " [23174.525]\n",
      " [23160.291]\n",
      " [23211.998]\n",
      " [23193.64 ]\n",
      " [23078.025]\n",
      " [23081.68 ]\n",
      " [23137.018]\n",
      " [23067.094]\n",
      " [23223.691]\n",
      " [23222.45 ]\n",
      " [23242.1  ]\n",
      " [23119.594]\n",
      " [23043.188]\n",
      " [23070.893]\n",
      " [23086.797]\n",
      " [23165.443]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predictions\n",
    "test_predictions *= std[3]\n",
    "test_predictions += mean[3]\n",
    "\n",
    "print(test_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:43:05.108351300Z",
     "start_time": "2024-01-18T13:43:05.091870Z"
    }
   },
   "id": "25a8b767a23b759c",
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets [-0.53124532 -0.52864757 -0.47726804 -0.12453867 -0.57420938  0.89239128\n",
      " -0.49883303 -0.58734333  1.37350985 -0.53164458 -0.31638877  1.44498178\n",
      " -0.33649674 -0.33499823 -0.66555595 -1.11252001 -0.47492954 -0.37344603\n",
      " -0.30018003 -0.84009806 -0.33025902 -0.44867201 -1.09768014 -0.69405865\n",
      " -0.54299485 -0.97873308  1.81890281 -0.51180624 -0.55093329 -0.79211479\n",
      "  1.44949804 -0.44059875 -0.50608185 -0.43746692 -0.46456445 -0.50878331\n",
      " -0.51321142 -0.5825056  -0.47876136  1.52859213 -0.4850976  -0.48850942\n",
      " -0.33372787 -0.51730767  1.96627479  0.96811503 -1.18937931 -0.40141466\n",
      " -0.36913718 -0.38647628  1.77203435 -0.55273772 -0.87554366 -0.82202785\n",
      " -0.70496818 -0.50724332  1.91022864 -0.92957798 -1.1114052  -0.49723082\n",
      " -0.42879737 -0.44921645  1.77577283  1.87107048 -0.86078676  1.47701038\n",
      " -0.38062226 -0.44213873  0.82950075  1.49172062  1.76576033 -1.00676912\n",
      " -0.44516167 -0.29987929 -0.61317569 -0.47677545 -0.66437374  1.35051376\n",
      "  1.34874563  1.78500238 -1.07436776  1.43236116 -0.65912119 -0.62439114\n",
      " -0.38049263  0.67536734 -0.33324047 -0.45019125 -0.47395474  0.88662022\n",
      "  1.47318893 -1.0952898  -0.57052793 -0.52165282 -0.6455465  -0.34908107\n",
      " -0.56185838 -0.93641199  1.4425344  -0.46877997 -0.55011923  1.81354656\n",
      "  1.34858489 -0.42152781  1.75813299 -0.47973617 -0.60445428  1.4425344\n",
      " -0.50568778 -0.56622945 -0.34460629 -0.62224449 -0.43407584 -0.83732919\n",
      " -0.50896997 -0.35729951 -0.49490269  1.51230561 -0.44252243  2.00544332\n",
      " -0.40640276  0.27172511  1.56319774  1.51155377 -0.45812451 -0.44062467\n",
      "  1.73732504  1.77619801]\n",
      "samples [[[-0.43472443 -0.43879691 -0.42637543 ...  0.3010783   1.11547647\n",
      "   -0.95884825]]\n",
      "\n",
      " [[-0.46427102 -0.46732643 -0.45507515 ... -0.1888407   0.94122307\n",
      "   -0.95884825]]\n",
      "\n",
      " [[-0.45098361 -0.46206135 -0.44710619 ...  0.74482859 -0.98151441\n",
      "    1.18519732]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.44688122 -0.43700575 -0.43379679 ... -0.24874035  0.91991809\n",
      "   -0.95884825]]\n",
      "\n",
      " [[ 1.69648373  1.6738488   1.68997169 ... -1.70942872  0.40038343\n",
      "   -0.95884825]]\n",
      "\n",
      " [[ 1.78659643  1.78390453  1.8072426  ...  0.48257093  1.18002939\n",
      "   -0.95884825]]]\n",
      "(array([[[-0.43472443, -0.43879691, -0.42637543, ...,  0.3010783 ,\n",
      "          1.11547647, -0.95884825]],\n",
      "\n",
      "       [[-0.46427102, -0.46732643, -0.45507515, ..., -0.1888407 ,\n",
      "          0.94122307, -0.95884825]],\n",
      "\n",
      "       [[-0.45098361, -0.46206135, -0.44710619, ...,  0.74482859,\n",
      "         -0.98151441,  1.18519732]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.44688122, -0.43700575, -0.43379679, ..., -0.24874035,\n",
      "          0.91991809, -0.95884825]],\n",
      "\n",
      "       [[ 1.69648373,  1.6738488 ,  1.68997169, ..., -1.70942872,\n",
      "          0.40038343, -0.95884825]],\n",
      "\n",
      "       [[ 1.78659643,  1.78390453,  1.8072426 , ...,  0.48257093,\n",
      "          1.18002939, -0.95884825]]]), array([-0.53124532, -0.52864757, -0.47726804, -0.12453867, -0.57420938,\n",
      "        0.89239128, -0.49883303, -0.58734333,  1.37350985, -0.53164458,\n",
      "       -0.31638877,  1.44498178, -0.33649674, -0.33499823, -0.66555595,\n",
      "       -1.11252001, -0.47492954, -0.37344603, -0.30018003, -0.84009806,\n",
      "       -0.33025902, -0.44867201, -1.09768014, -0.69405865, -0.54299485,\n",
      "       -0.97873308,  1.81890281, -0.51180624, -0.55093329, -0.79211479,\n",
      "        1.44949804, -0.44059875, -0.50608185, -0.43746692, -0.46456445,\n",
      "       -0.50878331, -0.51321142, -0.5825056 , -0.47876136,  1.52859213,\n",
      "       -0.4850976 , -0.48850942, -0.33372787, -0.51730767,  1.96627479,\n",
      "        0.96811503, -1.18937931, -0.40141466, -0.36913718, -0.38647628,\n",
      "        1.77203435, -0.55273772, -0.87554366, -0.82202785, -0.70496818,\n",
      "       -0.50724332,  1.91022864, -0.92957798, -1.1114052 , -0.49723082,\n",
      "       -0.42879737, -0.44921645,  1.77577283,  1.87107048, -0.86078676,\n",
      "        1.47701038, -0.38062226, -0.44213873,  0.82950075,  1.49172062,\n",
      "        1.76576033, -1.00676912, -0.44516167, -0.29987929, -0.61317569,\n",
      "       -0.47677545, -0.66437374,  1.35051376,  1.34874563,  1.78500238,\n",
      "       -1.07436776,  1.43236116, -0.65912119, -0.62439114, -0.38049263,\n",
      "        0.67536734, -0.33324047, -0.45019125, -0.47395474,  0.88662022,\n",
      "        1.47318893, -1.0952898 , -0.57052793, -0.52165282, -0.6455465 ,\n",
      "       -0.34908107, -0.56185838, -0.93641199,  1.4425344 , -0.46877997,\n",
      "       -0.55011923,  1.81354656,  1.34858489, -0.42152781,  1.75813299,\n",
      "       -0.47973617, -0.60445428,  1.4425344 , -0.50568778, -0.56622945,\n",
      "       -0.34460629, -0.62224449, -0.43407584, -0.83732919, -0.50896997,\n",
      "       -0.35729951, -0.49490269,  1.51230561, -0.44252243,  2.00544332,\n",
      "       -0.40640276,  0.27172511,  1.56319774,  1.51155377, -0.45812451,\n",
      "       -0.44062467,  1.73732504,  1.77619801]))\n"
     ]
    }
   ],
   "source": [
    "print(next(train_gen))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:56:50.507422600Z",
     "start_time": "2024-01-18T13:56:50.491224900Z"
    }
   },
   "id": "faf27b340f034d82",
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8642c79746983cd"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC_KLINES_YEARLY_2018_PER_30m 17374\n",
      "BTC_KLINES_YEARLY_2019_PER_30m 34817\n",
      "BTC_KLINES_YEARLY_2020_PER_30m 52276\n",
      "BTC_KLINES_YEARLY_2021_PER_30m 69745\n",
      "BTC_KLINES_YEARLY_2022_PER_30m 87245\n",
      "BTC_KLINES_YEARLY_2023_PER_30m 104743\n",
      "BTC_KLINES_YEARLY_2024_PER_30m 105911\n",
      "        openPrice  highPrice  lowPrice  closePrice  volume  quoteAssetVolume  \\\n",
      "0        16214.92   16372.99  16190.10    16298.00  483.71        7880124.16   \n",
      "1        16298.00   16333.00  16011.21    16168.00  408.26        6613629.87   \n",
      "2        16159.69   16400.00  16145.00    16369.80  525.96        8555658.67   \n",
      "3        16369.80   16488.98  16335.01    16403.01  363.64        5964801.34   \n",
      "4        16419.99   16639.00  16335.03    16612.02  475.17        7836295.46   \n",
      "...           ...        ...       ...         ...     ...               ...   \n",
      "105906   41801.10   41801.11  41691.24    41704.04  314.16       13111703.71   \n",
      "105907   41704.04   41729.41  41611.52    41623.93  455.54       18979308.52   \n",
      "105908   41623.92   41722.00  41602.01    41710.14  442.99       18455760.61   \n",
      "105909   41710.15   41710.15  41548.10    41624.73  562.92       23418771.09   \n",
      "105910   41624.73   41719.85  41421.21    41470.01  805.28       33469196.82   \n",
      "\n",
      "        tradesAmount  takerButBase  takerBuyQuote  close_minus5_d  ...  \\\n",
      "0               3934        269.80     4395847.06         -392.20  ...   \n",
      "1               3797        209.47     3395741.89         -461.86  ...   \n",
      "2               4824        295.31     4803950.93         -160.09  ...   \n",
      "3               3199        206.87     3393507.55            3.01  ...   \n",
      "4               3444        297.45     4905327.93          397.11  ...   \n",
      "...              ...           ...            ...             ...  ...   \n",
      "105906         14551        115.03     4800286.08         -164.19  ...   \n",
      "105907         18646        208.78     8698852.83         -220.33  ...   \n",
      "105908         17839        229.33     9555429.02          -97.41  ...   \n",
      "105909         17863        280.38    11664205.39         -137.75  ...   \n",
      "105910         28576        370.27    15393957.31         -331.10  ...   \n",
      "\n",
      "          psl_55  psl_80    psl_99   psl_150       pvo      pvos      pvoh  \\\n",
      "0       50.90909   53.75  55.55556  52.00000   0.25950  -8.21968   8.47917   \n",
      "1       49.09091   53.75  55.55556  52.00000   0.66606  -6.44253   7.10859   \n",
      "2       49.09091   55.00  56.56566  52.66667   3.30997  -4.49203   7.80200   \n",
      "3       50.90909   55.00  56.56566  53.33333   2.11994  -3.16964   5.28957   \n",
      "4       50.90909   56.25  57.57576  53.33333   3.34498  -1.86671   5.21169   \n",
      "...          ...     ...       ...       ...       ...       ...       ...   \n",
      "105906  49.09091   50.00  50.50505  50.00000 -38.20256 -35.56035  -2.64222   \n",
      "105907  49.09091   50.00  49.49495  49.33333 -33.85029 -35.21833   1.36804   \n",
      "105908  49.09091   51.25  49.49495  50.00000 -30.27720 -34.23011   3.95291   \n",
      "105909  49.09091   50.00  48.48485  49.33333 -24.83111 -32.35031   7.51920   \n",
      "105910  49.09091   50.00  47.47475  48.66667 -16.09389 -29.09902  13.00513   \n",
      "\n",
      "             qqe  qqel      qqes  \n",
      "0       50.31655   0.0  50.31655  \n",
      "1       48.46419   0.0  48.46419  \n",
      "2       48.46419   0.0  48.46419  \n",
      "3       48.46419   0.0  48.46419  \n",
      "4       48.46419   0.0  48.46419  \n",
      "...          ...   ...       ...  \n",
      "105906  58.13488   0.0  58.13488  \n",
      "105907  55.25546   0.0  55.25546  \n",
      "105908  55.00473   0.0  55.00473  \n",
      "105909  53.36450   0.0  53.36450  \n",
      "105910  50.07837   0.0  50.07837  \n",
      "\n",
      "[105911 rows x 277 columns]\n",
      "Index(['tradesAmount'], dtype='object')\n",
      "Index([], dtype='object')\n",
      "['cci_6', 'cci_14', 'cci_25', 'cci_35', 'cci_55', 'cci_80', 'cci_99', 'cci_150', 'bop']\n",
      "len before 105911\n",
      "len after 105456\n",
      "[[16214.92    16372.99    16190.1     ...    50.31655     0.\n",
      "     50.31655]\n",
      " [16298.      16333.      16011.21    ...    48.46419     0.\n",
      "     48.46419]\n",
      " [16159.69    16400.      16145.      ...    48.46419     0.\n",
      "     48.46419]\n",
      " ...\n",
      " [41623.92    41722.      41602.01    ...    55.00473     0.\n",
      "     55.00473]\n",
      " [41710.15    41710.15    41548.1     ...    53.3645      0.\n",
      "     53.3645 ]\n",
      " [41624.73    41719.85    41421.21    ...    50.07837     0.\n",
      "     50.07837]]\n",
      "train_max_range 94910\n",
      "val_max_range 105355\n",
      "[16298.   16168.   16369.8  ... 41710.14 41624.73 41470.01]\n",
      "std[3] 16334.747762447741\n",
      "[[-0.27602962 -0.27002695 -0.27369959 ... -0.0097632  -0.97278206\n",
      "   0.91559297]\n",
      " [-0.27094355 -0.27246536 -0.2846972  ... -0.18332304 -0.97278206\n",
      "   0.84709971]\n",
      " [-0.27941075 -0.26838001 -0.2764722  ... -0.18332304 -0.97278206\n",
      "   0.84709971]\n",
      " ...\n",
      " [ 1.27948481  1.27563724  1.28854644 ...  0.42950335 -0.97278206\n",
      "   1.08894411]\n",
      " [ 1.28476372  1.27491468  1.28523222 ...  0.27581936 -0.97278206\n",
      "   1.02829461]\n",
      " [ 1.27953439  1.27550614  1.27743141 ... -0.03207986 -0.97278206\n",
      "   0.90678597]]\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7442/170670426.py:172: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=500, epochs=30,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 29s 55ms/step - loss: 16.2112 - val_loss: 0.1466\n",
      "Epoch 2/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0842 - val_loss: 0.0521\n",
      "Epoch 3/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0600 - val_loss: 0.0646\n",
      "Epoch 4/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0510 - val_loss: 0.0373\n",
      "Epoch 5/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0458 - val_loss: 0.0482\n",
      "Epoch 6/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0417 - val_loss: 0.0337\n",
      "Epoch 7/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0387 - val_loss: 0.0345\n",
      "Epoch 8/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0365 - val_loss: 0.0454\n",
      "Epoch 9/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0348 - val_loss: 0.0402\n",
      "Epoch 10/30\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 0.0334 - val_loss: 0.0454\n",
      "Epoch 11/30\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 0.0319 - val_loss: 0.0420\n",
      "Epoch 12/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0309 - val_loss: 0.0426\n",
      "Epoch 13/30\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0298 - val_loss: 0.0351\n",
      "Epoch 14/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0287 - val_loss: 0.0391\n",
      "Epoch 15/30\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0279 - val_loss: 0.0429\n",
      "Epoch 16/30\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0273 - val_loss: 0.0398\n",
      "Epoch 17/30\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0267 - val_loss: 0.0418\n",
      "Epoch 18/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0258 - val_loss: 0.0423\n",
      "Epoch 19/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0254 - val_loss: 0.0472\n",
      "Epoch 20/30\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0249 - val_loss: 0.0379\n",
      "Epoch 21/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0242 - val_loss: 0.0413\n",
      "Epoch 22/30\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 0.0238 - val_loss: 0.0494\n",
      "Epoch 23/30\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 0.0233 - val_loss: 0.0379\n",
      "Epoch 24/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0226 - val_loss: 0.0430\n",
      "Epoch 25/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0224 - val_loss: 0.0426\n",
      "Epoch 26/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0222 - val_loss: 0.0399\n",
      "Epoch 27/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0215 - val_loss: 0.0448\n",
      "Epoch 28/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0215 - val_loss: 0.0422\n",
      "Epoch 29/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0211 - val_loss: 0.0451\n",
      "Epoch 30/30\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 0.0208 - val_loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import MaxPooling1D, Flatten, GRU, GlobalMaxPooling1D, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows), delay // step,))\n",
    "\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            futures = range(rows[j], rows[j] + delay, step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = [inner_list[3] for inner_list in data[futures]]\n",
    "            #targets[j] = data[rows[j] + delay][3]\n",
    "\n",
    "        yield samples, targets\n",
    "        \n",
    "TABLES = [ \"BTC_KLINES_YEARLY_2018_PER_30m\", \"BTC_KLINES_YEARLY_2019_PER_30m\", \"BTC_KLINES_YEARLY_2020_PER_30m\", \"BTC_KLINES_YEARLY_2021_PER_30m\", \"BTC_KLINES_YEARLY_2022_PER_30m\", \"BTC_KLINES_YEARLY_2023_PER_30m\", \"BTC_KLINES_YEARLY_2024_PER_30m\"]\n",
    "LIMITED_DOWN_TABLES = [\"BTC_KLINES_YEARLY_2017_PER_30m\",]\n",
    "\n",
    "engine = create_engine('postgresql://postgres:postgres@127.0.0.1/CryptoData')\n",
    "df = pd.DataFrame()\n",
    "for table in TABLES:\n",
    "    if table in LIMITED_DOWN_TABLES:\n",
    "        with engine.begin() as connection:\n",
    "            query = text(\"SELECT * FROM \\\"\" + table + \"\\\" ORDER BY \\\"ISOTimestampKlineCLOSE\\\" ASC OFFSET 155\")\n",
    "            df1 = pd.read_sql(query, con=connection)\n",
    "    else:\n",
    "        with engine.begin() as connection:\n",
    "            query = text(\"SELECT * FROM \\\"\" + table + \"\\\" ORDER BY \\\"ISOTimestampKlineCLOSE\\\" ASC\")\n",
    "            df1 = pd.read_sql(query, con=connection)\n",
    "\n",
    "    df = pd.concat([df, df1], axis=0, ignore_index=True)\n",
    "    print(table, len(df))\n",
    "\n",
    "\n",
    "df.drop(columns=['ISOInsertTimestamp', 'ISOTimestampKlineCLOSE', 'UNIXTimestampKlineOPEN', 'UNIXTimestampKlineCLOSE',\n",
    "                 'close_minus99_d', 'close_80_roc', 'close_99_roc', 'close_150_roc', 'mfi_80', 'mfi_99', 'mfi_150',\n",
    "                 'ftr_80', 'ftr_99', 'ftr_150','vr_6' ],\n",
    "        inplace=True)\n",
    "\n",
    "#df.drop(df.columns[15:], axis=1, inplace=True)\n",
    "print(df)\n",
    "\n",
    "print(df.select_dtypes(exclude=['float64']).columns)\n",
    "df['tradesAmount'] = df['tradesAmount'].astype('float64')\n",
    "print(df.select_dtypes(exclude=['float64']).columns)\n",
    "print( df.columns[df.isna().any()].tolist())\n",
    "print('len before', len(df))\n",
    "df = df.dropna(axis=0)\n",
    "print('len after', len(df))\n",
    "\n",
    "# print('len before', len(df))\n",
    "# # Convert 'tradesAmount' column to numeric, coerce errors to NaN\n",
    "# df['tradesAmount'] = pd.to_numeric(df['tradesAmount'], errors='coerce')\n",
    "# # Drop rows where 'tradesAmount' is NaN\n",
    "# df = df.dropna(subset=['tradesAmount'])\n",
    "# print('len after', len(df))\n",
    "\n",
    "np_array = df.to_numpy()\n",
    "print(np_array)\n",
    "\n",
    "train_max_range = int(0.9 * len(df))\n",
    "val_max_range = int(train_max_range + 0.1 * len(df) - 100)\n",
    "print('train_max_range', train_max_range )\n",
    "print('val_max_range', val_max_range )\n",
    "\n",
    "close_price = np_array[:, 3]\n",
    "print(close_price)\n",
    "\n",
    "mean = np_array[:train_max_range].mean(axis=0)\n",
    "np_array -= mean\n",
    "std = np_array[:train_max_range].std(axis=0)\n",
    "np_array /= std\n",
    "print('std[3]', std[3])\n",
    "\n",
    "print(np_array)\n",
    "\n",
    "lookback = 48\n",
    "step = 1\n",
    "delay = 24\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(np_array, lookback=lookback, delay=delay, min_index=0, max_index=train_max_range, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "val_gen = generator(np_array, lookback=lookback, delay=delay, min_index=train_max_range+1, max_index=val_max_range,\n",
    "                    shuffle=True, step=step, batch_size=batch_size)\n",
    "test_gen = generator(np_array, lookback=lookback, delay=delay, min_index=val_max_range+1, max_index=None, shuffle=True, step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (val_max_range - train_max_range - 1 - lookback) // batch_size\n",
    "test_steps = (len(np_array) - val_max_range - 1 - lookback) // batch_size\n",
    "\n",
    "###########################\n",
    "#POTENTIAL BUT HARD STABLE#\n",
    "###########################\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.5, return_sequences=True, input_shape=(None, np_array.shape[-1])))\n",
    "# model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.5))\n",
    "# #model.add(LSTM(128, activation='relu', dropout=0.1, recurrent_dropout=0.5))\n",
    "# model.add(Dense(delay))\n",
    "# \n",
    "# model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "\n",
    "####################\n",
    "##NOT BAD AND FAST##\n",
    "####################\n",
    "# model = Sequential()\n",
    "# #model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(None, np_array.shape[-1])))\n",
    "# model.add(Conv1D(64, kernel_size=3, input_shape=(None, np_array.shape[-1])))\n",
    "# model.add(MaxPooling1D(3))\n",
    "# # model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "# # model.add(MaxPooling1D(2))\n",
    "# # model.add(Flatten())\n",
    "# \n",
    "# \n",
    "# model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.5, return_sequences=True))\n",
    "# model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.5))\n",
    "# #model.add(LSTM(128, activation='relu', dropout=0.1, recurrent_dropout=0.5))\n",
    "# model.add(Dense(delay))\n",
    "# \n",
    "# model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "#wstepnie bylo 32/64 na lstmach\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.0, recurrent_dropout=0.3, return_sequences=True, input_shape=(None, np_array.shape[-1])))\n",
    "model.add(LSTM(256, activation='relu', dropout=0.0, recurrent_dropout=0.0))\n",
    "#model.add(LSTM(32, dropout=0.0, recurrent_dropout=0.5))\n",
    "model.add(Dense(delay))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "\n",
    "#########\n",
    "#TO CHECK ON BIGGER DATA SET#\n",
    "#########\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add((LSTM(units=100, return_sequences=True, input_shape=(None, np_array.shape[-1]))))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add((LSTM(units=80, return_sequences=True)))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(LSTM(units=50, return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=30))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(delay))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "#200-60\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=500, epochs=30,\n",
    "                              validation_data=val_gen, validation_steps=val_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:22:42.593875007Z",
     "start_time": "2024-01-27T11:08:48.223960262Z"
    }
   },
   "id": "efe63b523984a41d"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Strata trenowania')\n",
    "plt.plot(epochs, val_loss, 'b', label='Strata walidacji')\n",
    "plt.title('Strata trenowania i walidacji')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:22:56.627646093Z",
     "start_time": "2024-01-27T11:22:56.558421859Z"
    }
   },
   "id": "25c8f8b79fe91ea1"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC_KLINES_YEARLY_2024_PER_1h 356\n",
      "     openPrice  highPrice  lowPrice  closePrice    volume  quoteAssetVolume  \\\n",
      "0     45866.57   45944.12  45573.44    45779.02   2155.66      9.869257e+07   \n",
      "1     45779.02   45904.66  45250.01    45442.02   5702.98      2.595455e+08   \n",
      "2     45442.01   45459.28  44333.44    44462.01   9485.41      4.250655e+08   \n",
      "3     44462.00   44675.88  43212.00    43624.00  12653.69      5.563036e+08   \n",
      "4     43623.99   43836.88  43278.00    43803.99   6405.61      2.789715e+08   \n",
      "..         ...        ...       ...         ...       ...               ...   \n",
      "351   41815.01   41875.67  41791.10    41844.26    491.10      2.054564e+07   \n",
      "352   41844.26   41890.00  41738.59    41762.48    435.47      1.820546e+07   \n",
      "353   41762.49   41812.00  41691.24    41704.04    559.97      2.338461e+07   \n",
      "354   41704.04   41729.41  41602.01    41710.14    898.52      3.743507e+07   \n",
      "355   41710.15   41719.85  41421.21    41470.01   1368.20      5.688797e+07   \n",
      "\n",
      "     tradesAmount  takerButBase  takerBuyQuote  close_minus5_d  ...    psl_55  \\\n",
      "0           98359       1009.47   4.621726e+07          -80.99  ...  40.00000   \n",
      "1          172179       3078.14   1.400625e+08         -483.90  ...  40.00000   \n",
      "2          296919       4300.06   1.926358e+08        -1601.61  ...  40.00000   \n",
      "3          390704       5811.91   2.556676e+08        -2330.35  ...  38.18182   \n",
      "4          172068       3308.29   1.440827e+08        -2062.57  ...  40.00000   \n",
      "..            ...           ...            ...             ...  ...       ...   \n",
      "351         22163        231.58   9.689163e+06           20.75  ...  52.72727   \n",
      "352         25185        189.27   7.912656e+06          -23.46  ...  50.90909   \n",
      "353         25954        219.48   9.165421e+06         -114.82  ...  49.09091   \n",
      "354         36485        438.11   1.825428e+07         -128.45  ...  49.09091   \n",
      "355         46439        650.65   2.705816e+07         -345.00  ...  49.09091   \n",
      "\n",
      "     psl_80    psl_99   psl_150       pvo      pvos      pvoh       qqe  qqel  \\\n",
      "0     43.75  44.44444  50.00000 -21.42819 -23.93866   2.51047  49.41821   0.0   \n",
      "1     42.50  43.43434  49.33333  -6.85058 -20.52105  13.67047  47.11816   0.0   \n",
      "2     41.25  42.42424  49.33333  12.09878 -13.99708  26.09586  42.29219   0.0   \n",
      "3     41.25  42.42424  48.66667  27.77940  -5.64178  33.42119  37.34942   0.0   \n",
      "4     42.50  43.43434  49.33333  27.34583   0.95574  26.39009  35.23577   0.0   \n",
      "..      ...       ...       ...       ...       ...       ...       ...   ...   \n",
      "351   53.75  52.52525  49.33333 -21.80091  -6.72053 -15.08038  72.17096   0.0   \n",
      "352   52.50  51.51515  49.33333 -25.56743 -10.48991 -15.07752  70.88196   0.0   \n",
      "353   51.25  51.51515  49.33333 -27.87465 -13.96686 -13.90779  69.23537   0.0   \n",
      "354   51.25  51.51515  49.33333 -27.21664 -16.61681 -10.59983  68.18171   0.0   \n",
      "355   50.00  50.50505  48.66667 -23.06477 -17.90641  -5.15837  64.46743   0.0   \n",
      "\n",
      "         qqes  \n",
      "0    49.41821  \n",
      "1    47.11816  \n",
      "2    42.29219  \n",
      "3    37.34942  \n",
      "4    35.23577  \n",
      "..        ...  \n",
      "351  72.17096  \n",
      "352  70.88196  \n",
      "353  69.23537  \n",
      "354  68.18171  \n",
      "355  64.46743  \n",
      "\n",
      "[356 rows x 277 columns]\n",
      "AAAAAAA [[[4.586657e+04 4.594412e+04 4.557344e+04 ... 4.941821e+01 0.000000e+00\n",
      "   4.941821e+01]\n",
      "  [4.577902e+04 4.590466e+04 4.525001e+04 ... 4.711816e+01 0.000000e+00\n",
      "   4.711816e+01]\n",
      "  [4.544201e+04 4.545928e+04 4.433344e+04 ... 4.229219e+01 0.000000e+00\n",
      "   4.229219e+01]\n",
      "  ...\n",
      "  [4.305241e+04 4.306656e+04 4.286590e+04 ... 4.338202e+01 4.338202e+01\n",
      "   0.000000e+00]\n",
      "  [4.288904e+04 4.293875e+04 4.275934e+04 ... 4.338202e+01 4.338202e+01\n",
      "   0.000000e+00]\n",
      "  [4.282999e+04 4.284720e+04 4.271000e+04 ... 4.338202e+01 4.338202e+01\n",
      "   0.000000e+00]]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "TABLES_TEST = [\"BTC_KLINES_YEARLY_2024_PER_1h\"]\n",
    "df_test = pd.DataFrame()\n",
    "offset_test = '67'\n",
    "for table in TABLES_TEST:\n",
    "    with engine.begin() as connection:\n",
    "        query = text(\"SELECT * FROM \\\"\" + table + \"\\\" ORDER BY \\\"ISOTimestampKlineCLOSE\\\" ASC OFFSET \" + offset_test)\n",
    "        df_test1 = pd.read_sql(query, con=connection)\n",
    "    df_test = pd.concat([df_test, df_test1], axis=0, ignore_index=True)\n",
    "    print(table, len(df_test))\n",
    "    \n",
    "df_test.drop(columns=['ISOInsertTimestamp', 'ISOTimestampKlineCLOSE', 'UNIXTimestampKlineOPEN', 'UNIXTimestampKlineCLOSE',\n",
    "                 'close_minus99_d', 'close_80_roc', 'close_99_roc', 'close_150_roc', 'mfi_80', 'mfi_99', 'mfi_150',\n",
    "                 'ftr_80', 'ftr_99', 'ftr_150','vr_6' ],\n",
    "        inplace=True)\n",
    "print(df_test)\n",
    "\n",
    "np_array_test = df_test.to_numpy()    \n",
    "    \n",
    "test_gen = generator(np_array_test, lookback=lookback, delay=delay, min_index=0, max_index=None, shuffle=False, step=step,\n",
    "                      batch_size=1)\n",
    "\n",
    "# for i in range (1,100):\n",
    "a = next(test_gen)[0]\n",
    "print('AAAAAAA', a)\n",
    "print(len(a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:23:00.651517522Z",
     "start_time": "2024-01-27T11:23:00.616526371Z"
    }
   },
   "id": "6f8bea688e438c62"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[7.49239576e+08 7.50506335e+08 7.44451371e+08 ... 8.27957904e+05\n",
      "   2.07239088e+04 8.27957904e+05]\n",
      "  [7.47809468e+08 7.49861766e+08 7.39168224e+08 ... 7.90387167e+05\n",
      "   2.07239088e+04 7.90387167e+05]\n",
      "  [7.42304495e+08 7.42586596e+08 7.24196284e+08 ... 7.11556165e+05\n",
      "   2.07239088e+04 7.11556165e+05]\n",
      "  ...\n",
      "  [7.03270982e+08 7.03502119e+08 7.00224388e+08 ... 7.29358263e+05\n",
      "   7.29358263e+05 2.07239088e+04]\n",
      "  [7.00602374e+08 7.01414374e+08 6.98483757e+08 ... 7.29358263e+05\n",
      "   7.29358263e+05 2.07239088e+04]\n",
      "  [6.99637807e+08 6.99918928e+08 6.97677801e+08 ... 7.29358263e+05\n",
      "   7.29358263e+05 2.07239088e+04]]]\n"
     ]
    }
   ],
   "source": [
    "test_predictions =  a\n",
    "test_predictions *= std[3]\n",
    "test_predictions += mean[3]\n",
    "print(test_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:23:01.988707536Z",
     "start_time": "2024-01-27T11:23:01.983089431Z"
    }
   },
   "id": "5c191ab759c2455b"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n",
      "[[0.46495867 0.46406555 0.44527942 0.43797076 0.4284643  0.50491405\n",
      "  0.5103112  0.47435543 0.4782848  0.5131923  0.4553817  0.4219403\n",
      "  0.47709632 0.45805734 0.4456898  0.48738605 0.45890576 0.48268995\n",
      "  0.47479546 0.4825672  0.45392695 0.5144422  0.44161236 0.49291837]]\n"
     ]
    }
   ],
   "source": [
    "z = model.predict(a)\n",
    "print(z)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:23:02.755669038Z",
     "start_time": "2024-01-27T11:23:02.598978551Z"
    }
   },
   "id": "112732a2d24a41d4"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[28318.89 , 28304.303, 27997.436, 27878.05 , 27722.766, 28971.55 ,\n        29059.713, 28472.385, 28536.57 , 29106.775, 28162.453, 27616.197,\n        28517.156, 28206.16 , 28004.139, 28685.236, 28220.018, 28608.527,\n        28479.572, 28606.521, 28138.691, 29127.191, 27937.535, 28775.605]],\n      dtype=float32)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictionsz =  z\n",
    "test_predictionsz *= std[3]\n",
    "test_predictionsz += mean[3]\n",
    "test_predictionsz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T11:23:06.059178147Z",
     "start_time": "2024-01-27T11:23:06.015162062Z"
    }
   },
   "id": "998492fd678aac8c"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "symetrical = test_predictions + test_predictions[::-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:00:11.475149500Z",
     "start_time": "2024-01-19T12:00:11.446650200Z"
    }
   },
   "id": "6a510bcd676f13f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c180c45f03bde0d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
